{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clduab11/judicAIta/blob/main/examples/notebooks/train_tunix_reasoning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n32mE_hKL1eB"
      },
      "source": [
        "# Judicaita: GRPO Training with Google Tunix on TPU\n",
        "\n",
        "## \ud83c\udfaf Hackathon Context\n",
        "\n",
        "This notebook demonstrates **GRPO (Group Relative Policy Optimization)** training for the Judicaita legal AI assistant using:\n",
        "- **Google Tunix** for RL training infrastructure\n",
        "- **Gemma 3-1B-IT** as the base model\n",
        "- **TPU v2-8+** for accelerated training\n",
        "- **LoRA adapters** for parameter-efficient fine-tuning\n",
        "\n",
        "This is developed for the Kaggle hackathon to train models that generate explainable legal reasoning with structured XML-formatted outputs.\n",
        "\n",
        "## \u26a1 TPU Requirements\n",
        "\n",
        "**IMPORTANT**: This notebook requires:\n",
        "- Google Colab with TPU runtime (TPU v2-8 or higher)\n",
        "- Runtime type: TPU (not CPU or GPU)\n",
        "- To enable: Runtime \u2192 Change runtime type \u2192 Hardware accelerator: TPU\n",
        "\n",
        "## \ud83d\udccb What This Notebook Does\n",
        "\n",
        "1. **Environment Setup**: Install Tunix, JAX, and dependencies for TPU\n",
        "2. **Model Loading**: Download and initialize Gemma 3-1B-IT with LoRA\n",
        "3. **Dataset Preparation**: Format training data with XML-tagged reasoning\n",
        "4. **Reward Function**: Multi-objective scoring including **Legal Accuracy**, **Reasoning Coherence**, **Answer Correctness** (35%), Format, and Length.\n",
        "5. **GRPO Training**: Train with `GRPOLearner` and `RLCluster` on TPU\n",
        "6. **Export**: Package trained LoRA adapters for Kaggle submission\n",
        "\n",
        "## \ud83d\udd04 Data Flow\n",
        "\n",
        "```\n",
        "Dataset \u2192 Prompts \u2192 Model Rollouts \u2192 Reward Scoring \u2192 GRPO Updates\n",
        "                                                           \u2193\n",
        "                                              LoRA Adapter Checkpoints\n",
        "```\n",
        "\n",
        "## \u26a0\ufe0f Differences from Main Codebase\n",
        "\n",
        "| Aspect | Main Codebase | This Notebook |\n",
        "|--------|---------------|---------------|\n",
        "| Format | Step-by-step format | XML `<reasoning>`/`<answer>` |\n",
        "| Framework | PyTorch | JAX/Flax |\n",
        "| Training | Custom GRPO | Tunix GRPOLearner |\n",
        "| Hardware | GPU/CPU | TPU v2-8+ |\n",
        "\n",
        "## \ud83d\udcda References\n",
        "\n",
        "- [Google Tunix Documentation](https://tunix.readthedocs.io/)\n",
        "- [Tunix GRPO Gemma Example](https://github.com/google/tunix/tree/main/examples/grpo_gemma)\n",
        "- [Gemma Model Card](https://ai.google.dev/gemma/docs)\n",
        "- [GRPO Paper](https://arxiv.org/abs/2402.03300)\n",
        "- [Judicaita Repository](https://github.com/clduab11/judicAIta)\n",
        "\n",
        "## \u26a0\ufe0f Known Limitations\n",
        "\n",
        "- **TPU Required**: Cannot run on CPU/GPU without code modifications\n",
        "- **Memory**: TPU v2-8 has ~64GB; larger models may need v3 or higher\n",
        "- **Dataset**: Assumes generic legal reasoning tasks (not LegalBench-specific)\n",
        "- **Checkpoints**: Large checkpoint files may exceed Colab storage limits\n",
        "- **API Stability**: Tunix API may change; verify imports match your version\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwgwQnSXL1eD"
      },
      "source": [
        "## \ud83d\udce6 Step 1: Install Dependencies\n",
        "\n",
        "Install required packages for TPU training with Tunix and Gemma."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFytxSM9L1eD",
        "outputId": "895586b1-e083-4f2f-e81c-3aa0216cd82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting git+https://github.com/google/tunix\n",
            "  Cloning https://github.com/google/tunix to /tmp/pip-req-build-ln6fnr01\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/tunix /tmp/pip-req-build-ln6fnr01\n",
            "  Resolved https://github.com/google/tunix to commit 3b558520bb65e4cd649f8199362f9dc144e541da\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (4.4.2)\n",
            "Requirement already satisfied: flax>=0.11.1 in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (2025.10.0)\n",
            "Requirement already satisfied: google-metrax>=0.2.3 in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.2.4)\n",
            "Requirement already satisfied: grain in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.2.15)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.36.0)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.3.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (3.1.6)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.3.13)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.63.1)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (2.3.0)\n",
            "Requirement already satisfied: pylatexenc in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (2.10)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (1.2.1)\n",
            "Requirement already satisfied: qwix in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.1.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.2.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (1.14.0)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (4.9.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (4.67.1)\n",
            "Requirement already satisfied: transformers<=4.57.1 in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (4.57.1)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from google-tunix==0.1.6) (0.1.9)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (2.1.3)\n",
            "Requirement already satisfied: jax>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (0.8.3.dev20251228+c7ad0967d)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (1.1.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (0.2.6)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (0.11.31)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (0.1.80)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (14.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (4.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (6.0.3)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax>=0.11.1->google-tunix==0.1.6) (0.1.10)\n",
            "Requirement already satisfied: clu>=0.0.12 in /usr/local/lib/python3.12/dist-packages (from google-metrax>=0.2.3->google-tunix==0.1.6) (0.0.12)\n",
            "Requirement already satisfied: tensorboardx>=2.6.4 in /usr/local/lib/python3.12/dist-packages (from google-metrax>=0.2.3->google-tunix==0.1.6) (2.6.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers<=4.57.1->google-tunix==0.1.6) (3.20.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.57.1->google-tunix==0.1.6) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.57.1->google-tunix==0.1.6) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers<=4.57.1->google-tunix==0.1.6) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.57.1->google-tunix==0.1.6) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<=4.57.1->google-tunix==0.1.6) (0.7.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->google-tunix==0.1.6) (1.2.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->google-tunix==0.1.6) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->google-tunix==0.1.6) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets->google-tunix==0.1.6) (2.3.3)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->google-tunix==0.1.6) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->google-tunix==0.1.6) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets->google-tunix==0.1.6) (0.70.18)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from grain->google-tunix==0.1.6) (2.3.1)\n",
            "Requirement already satisfied: array-record>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from grain->google-tunix==0.1.6) (0.8.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from grain->google-tunix==0.1.6) (3.1.2)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from grain->google-tunix==0.1.6) (1.13.0)\n",
            "Requirement already satisfied: protobuf>=5.28.3 in /usr/local/lib/python3.12/dist-packages (from grain->google-tunix==0.1.6) (5.29.5)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from jaxtyping->google-tunix==0.1.6) (0.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->google-tunix==0.1.6) (3.0.3)\n",
            "Requirement already satisfied: llvmlite<0.47,>=0.46.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->google-tunix==0.1.6) (0.46.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->google-tunix==0.1.6) (4.9.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from qwix->google-tunix==0.1.6) (0.8.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->google-tunix==0.1.6) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (0.1.9)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (4.2.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (7.2.0)\n",
            "Requirement already satisfied: simple_parsing in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (0.1.7)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (1.17.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (3.2.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from tensorflow_datasets->google-tunix==0.1.6) (2.0.1)\n",
            "Requirement already satisfied: ml-collections in /usr/local/lib/python3.12/dist-packages (from clu>=0.0.12->google-metrax>=0.2.3->google-tunix==0.1.6) (1.1.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets->google-tunix==0.1.6) (0.8.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets->google-tunix==0.1.6) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow_datasets->google-tunix==0.1.6) (3.23.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets->google-tunix==0.1.6) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->google-tunix==0.1.6) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->google-tunix==0.1.6) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->google-tunix==0.1.6) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets->google-tunix==0.1.6) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets->google-tunix==0.1.6) (0.16.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.1->flax>=0.11.1->google-tunix==0.1.6) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.1->flax>=0.11.1->google-tunix==0.1.6) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.1->flax>=0.11.1->google-tunix==0.1.6) (1.16.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<=4.57.1->google-tunix==0.1.6) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers<=4.57.1->google-tunix==0.1.6) (2.6.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.11.1->google-tunix==0.1.6) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.11.1->google-tunix==0.1.6) (2.19.2)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree->tensorflow_datasets->google-tunix==0.1.6) (25.4.0)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax->flax>=0.11.1->google-tunix==0.1.6) (0.1.91)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.11.1->google-tunix==0.1.6) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.11.1->google-tunix==0.1.6) (25.1.0)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.11.1->google-tunix==0.1.6) (4.15.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.11.1->google-tunix==0.1.6) (3.20.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->google-tunix==0.1.6) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->google-tunix==0.1.6) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets->google-tunix==0.1.6) (2025.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from promise->tensorflow_datasets->google-tunix==0.1.6) (1.17.0)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.12/dist-packages (from simple_parsing->tensorflow_datasets->google-tunix==0.1.6) (0.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.12/dist-packages (from tensorflow-metadata->tensorflow_datasets->google-tunix==0.1.6) (1.72.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->google-tunix==0.1.6) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->google-tunix==0.1.6) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->google-tunix==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->google-tunix==0.1.6) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->google-tunix==0.1.6) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets->google-tunix==0.1.6) (1.22.0)\n",
            "Requirement already satisfied: toolz>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax->flax>=0.11.1->google-tunix==0.1.6) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.11.1->google-tunix==0.1.6) (0.1.2)\n",
            "Collecting git+https://github.com/google/qwix\n",
            "  Cloning https://github.com/google/qwix to /tmp/pip-req-build-9crn6m1f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/qwix /tmp/pip-req-build-9crn6m1f\n",
            "  Resolved https://github.com/google/qwix to commit 10a0a2139c919d3ae1510acc5092122f366c94cb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from qwix==0.1.5) (0.8.3.dev20251228+c7ad0967d)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from qwix==0.1.5) (0.8.2)\n",
            "Requirement already satisfied: flax>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from qwix==0.1.5) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (2.1.3)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (1.1.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (0.2.6)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (0.11.31)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (0.1.80)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (14.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (4.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (6.0.3)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax>=0.12.0->qwix==0.1.5) (0.1.10)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->qwix==0.1.5) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->qwix==0.1.5) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax->qwix==0.1.5) (1.16.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.12.0->qwix==0.1.5) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax>=0.12.0->qwix==0.1.5) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from optax->flax>=0.12.0->qwix==0.1.5) (2.3.1)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax->flax>=0.12.0->qwix==0.1.5) (0.1.91)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (25.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (4.15.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (3.20.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (7.2.0)\n",
            "Requirement already satisfied: toolz>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax->flax>=0.12.0->qwix==0.1.5) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.12.0->qwix==0.1.5) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (2025.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax>=0.12.0->qwix==0.1.5) (3.23.0)\n",
            "Collecting git+https://github.com/google/flax\n",
            "  Cloning https://github.com/google/flax to /tmp/pip-req-build-ma7tzp1y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/google/flax /tmp/pip-req-build-ma7tzp1y\n",
            "  Resolved https://github.com/google/flax to commit 3f2ff40e8cd8b30aea2ef984ef4a76e11384e132\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (2.1.3)\n",
            "Requirement already satisfied: jax>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (0.8.3.dev20251228+c7ad0967d)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (1.1.2)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (0.2.6)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (0.11.31)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (0.1.80)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (14.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (4.15.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (6.0.3)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.12/dist-packages (from flax==0.12.2) (0.1.10)\n",
            "Requirement already satisfied: jaxlib<=0.8.3,>=0.8.2 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.1->flax==0.12.2) (0.8.2)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.1->flax==0.12.2) (0.5.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.1->flax==0.12.2) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.13 in /usr/local/lib/python3.12/dist-packages (from jax>=0.8.1->flax==0.12.2) (1.16.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax==0.12.2) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1->flax==0.12.2) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from optax->flax==0.12.2) (2.3.1)\n",
            "Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.12/dist-packages (from optax->flax==0.12.2) (0.1.91)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.2) (1.13.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.2) (1.6.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.2) (25.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.2) (5.29.5)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.2) (4.15.0)\n",
            "Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.2) (3.20.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from orbax-checkpoint->flax==0.12.2) (7.2.0)\n",
            "Requirement already satisfied: toolz>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from chex>=0.1.87->optax->flax==0.12.2) (1.1.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax==0.12.2) (0.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax==0.12.2) (2025.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax==0.12.2) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax==0.12.2) (3.23.0)\n",
            "Building wheels for collected packages: flax\n",
            "  Building wheel for flax (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flax: filename=flax-0.12.2-py3-none-any.whl size=488216 sha256=ba375d560ebd6569a7f9c36fd5d9ad77106a830a539cf892ff735bc0f2691a35\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ixg9jt5s/wheels/1c/1c/50/70e06d9ee1df89d65ab742227bddb43d8e4eea822db6757377\n",
            "Successfully built flax\n",
            "Installing collected packages: flax\n",
            "Successfully installed flax-0.12.2\n",
            "\u2705 Dependencies installed! Please restart runtime: Runtime \u2192 Restart runtime\n"
          ]
        }
      ],
      "source": [
        "# Install core dependencies (based on official Google Tunix GRPO notebook)\n",
        "%pip install -q dotenv kagglehub ipywidgets tensorflow tensorflow_datasets tensorboardX\n",
        "%pip install -q transformers>=4.40.0 grain huggingface_hub>=0.20.0 datasets>=2.14.0\n",
        "%pip install -q 'numpy>2' sentencepiece>=0.1.99 safetensors>=0.4.0\n",
        "# Install JAX, Tunix, Qwix, and Flax from GitHub\n",
        "%pip install -q git+https://github.com/jax-ml/jax\n",
        "%pip install git+https://github.com/google/tunix\n",
        "%pip install git+https://github.com/google/qwix\n",
        "%pip uninstall -q flax -y\n",
        "%pip install git+https://github.com/google/flax\n",
        "\n",
        "print(\"\u2705 Dependencies installed! Please restart runtime: Runtime \u2192 Restart runtime\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udd0d VALIDATION: Verify installed package versions\n",
        "print(\"\ud83d\udce6 Phase 1 Validation - Step 1: Package Versions\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "!pip show google-tunix 2>/dev/null | grep -E \"Name|Version\" || echo \"\u26a0\ufe0f  google-tunix not found\"\n",
        "!pip show jax 2>/dev/null | grep -E \"Name|Version\" || echo \"\u26a0\ufe0f  jax not found\"\n",
        "!pip show flax 2>/dev/null | grep -E \"Name|Version\" || echo \"\u26a0\ufe0f  flax not found\"\n",
        "\n",
        "print(\"\\n\u2705 Package verification complete!\")\n",
        "print(\"\\n\u26a0\ufe0f  Expected versions:\")\n",
        "print(\"   \u2022 google-tunix: 0.1.0 - 0.1.6\")\n",
        "print(\"   \u2022 jax: TPU-compatible (0.8.x)\")\n",
        "print(\"   \u2022 flax: 0.12.x\")\n",
        "print(\"\\n\u26a0\ufe0f  Note: jax_cuda12_plugin warnings are harmless on TPU runtime\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udccb Phase 1: Environment Validation\n",
        "\n",
        "> **Purpose:** Validate environment setup before proceeding to training.\n",
        "\n",
        "**Colab Runtime Requirements:**\n",
        "- \u2705 Runtime must be set to TPU: **Runtime \u2192 Change runtime type \u2192 TPU**\n",
        "- \u2705 TPU v2-8 or higher recommended\n",
        "- \u2705 Restart runtime after Step 1 installation completes\n",
        "\n",
        "**Expected Installation Behavior:**\n",
        "- `jax_cuda12_plugin` warnings are **harmless** on Colab TPU\n",
        "- These warnings appear because Colab has GPU packages pre-installed alongside TPU runtime\n",
        "- They do **NOT** affect TPU training functionality\n",
        "\n",
        "**Dependency Version Requirements:**\n",
        "\n",
        "| Package | Required Version | Notes |\n",
        "|---------|------------------|-------|\n",
        "| `google-tunix` | `>=0.1.0,<=0.1.5` | Max available is 0.1.5 (Dec 2025) |\n",
        "| `jax[tpu]` | TPU-compatible | Use official libtpu releases |\n",
        "| `flax` | `0.10.2` | Compatible with JAX TPU builds |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udccb Phase 1: Verify Package Versions (run after Step 1 installation)\n",
        "print(\"\ud83d\udce6 Package Version Verification\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def get_package_version(package_name):\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, '-m', 'pip', 'show', package_name],\n",
        "            capture_output=True, text=True\n",
        "        )\n",
        "        for line in result.stdout.split('\\n'):\n",
        "            if line.startswith('Version:'):\n",
        "                return line.split(':')[1].strip()\n",
        "    except:\n",
        "        pass\n",
        "    return 'Not installed'\n",
        "\n",
        "packages_to_check = {\n",
        "    'google-tunix': 'Tunix (0.1.0-0.1.5 expected)',\n",
        "    'jax': 'JAX (TPU-compatible)',\n",
        "    'flax': 'Flax (0.10.2 expected)',\n",
        "}\n",
        "\n",
        "for pkg, description in packages_to_check.items():\n",
        "    version = get_package_version(pkg)\n",
        "    status = '\u2705' if version != 'Not installed' else '\u274c'\n",
        "    print(f\"{status} {description}: {version}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"\u26a0\ufe0f IMPORTANT: Restart runtime after this step!\")\n",
        "print(\"   Do NOT re-run Step 1 after restart.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5LS68YDL1eE"
      },
      "source": [
        "### \ud83d\udcdd Version Compatibility Summary\n",
        "\n",
        "| Package | Version Range | Notes |\n",
        "|---------|---------------|-------|\n",
        "| google-tunix | 0.1.0 - 0.1.5 | Max available version is 0.1.5 (as of Dec 2025) |\n",
        "| JAX | TPU-compatible | Use `jax[tpu]` with libtpu releases for Colab TPU |\n",
        "| Flax | 0.10.2 | Compatible with JAX TPU builds |\n",
        "\n",
        "**Expected Warnings:**\n",
        "- `jax_cuda12_plugin` warnings are harmless for TPU training\n",
        "- These warnings appear because Colab environments may have GPU packages pre-installed\n",
        "\n",
        "**Important:** After running the install cell above, you must restart the runtime for TPU libraries to be properly loaded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## \u26a0\ufe0f CRITICAL: Runtime Restart Checkpoint\n",
        "\n",
        "### \ud83d\uded1 STOP HERE AND RESTART RUNTIME\n",
        "\n",
        "**Before proceeding, complete this checklist:**\n",
        "\n",
        "- [ ] Step 1 dependency installation completed successfully\n",
        "- [ ] Package versions verified (Tunix 0.1.x, JAX TPU-compatible, Flax 0.10.2)\n",
        "- [ ] **Restart runtime now:** `Runtime \u2192 Restart runtime`\n",
        "\n",
        "**After restart:**\n",
        "- [ ] Do **NOT** re-run Step 1 (dependencies already installed)\n",
        "- [ ] Continue from Step 2 below\n",
        "\n",
        "---\n",
        "\n",
        "**Why restart is required:**\n",
        "- TPU libraries need fresh Python interpreter to initialize correctly\n",
        "- JAX TPU backend must be loaded before any JAX operations\n",
        "- Skipping restart will cause `RuntimeError: TPU not found`\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WvlgQSnL1eE"
      },
      "source": [
        "## \ud83d\ude80 Step 2: Initialize TPU Runtime\n",
        "\n",
        "Set up JAX to use TPU devices and import core Tunix modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DIUtOIfwL1eE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "b4846aec-07b2-4c3a-d720-62079ea5b0b5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-3366999836.py, line 40)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3366999836.py\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    print(\"\u2705 JAX distributed initialized successfully!\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ],
      "source": [
        "# Core imports for GRPO training (based on official Google Tunix GRPO notebook)\n",
        "import functools\n",
        "from pprint import pprint\n",
        "import re\n",
        "import sys\n",
        "\n",
        "import csv\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "from flax import nnx\n",
        "import grain\n",
        "import humanize\n",
        "from huggingface_hub import snapshot_download\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "from orbax import checkpoint as ocp\n",
        "from pathlib import Path\n",
        "import qwix\n",
        "from tqdm.auto import tqdm\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Tunix imports (correct paths for GRPO)\n",
        "from tunix.generate import sampler as sampler_lib\n",
        "from tunix.generate import tokenizer_adapter as tokenizer_lib\n",
        "from tunix.models.gemma3 import model as gemma_lib\n",
        "from tunix.models.gemma3 import params_safetensors as params_safetensors_lib\n",
        "from tunix.models.gemma3 import params as gemma_params\n",
        "from tunix.rl import rl_cluster as rl_cluster_lib\n",
        "from tunix.rl.grpo.grpo_learner import GRPOConfig, GRPOLearner\n",
        "from tunix.rl.rollout import base_rollout\n",
        "from tunix.sft import metrics_logger\n",
        "\n",
        "# Initialize TPU\n",
        "print(\"Initializing TPU runtime...\")\n",
        "try:\n",
        "    jax.distributed.initialize()\n",
        "    print(\"\u2705 JAX distributed initialized successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\u26a0\ufe0f JAX distributed initialization: {e}\")\n",
        "    print(\"   This is normal for single-host setups\")\n",
        "\n",
        "# Verify TPU devices\n",
        "devices = jax.devices()\n",
        "print(f\"\\\\n\ud83d\udda5\ufe0f TPU Device Information:\")\n",
        "print(f\"    Number of devices: {len(devices)}\")\n",
        "print(f\"    Device type: {devices[0].platform}\")\n",
        "print(f\"    Devices: {devices}\")\n",
        "\n",
        "if len(devices) == 0:\n",
        "    raise RuntimeError(\"No TPU devices detected! Please check your runtime configuration.\")\n",
        "\n",
        "print(\"\\\\n\u2705 TPU setup complete and verified!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udccb Phase 1: TPU Detection and Import Verification\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', message='.*jax_cuda12_plugin.*')\n",
        "\n",
        "import sys\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"\ud83d\udccb PHASE 1: TPU & IMPORT VERIFICATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# JAX verification\n",
        "print(\"\\n\ud83d\udd0d JAX Verification:\")\n",
        "print(f\"   JAX version: {jax.__version__}\")\n",
        "devices = jax.devices()\n",
        "print(f\"   Number of devices: {len(devices)}\")\n",
        "if len(devices) > 0:\n",
        "    print(f\"   Device type: {devices[0].platform}\")\n",
        "else:\n",
        "    print(\"   \u26a0\ufe0f No devices found\")\n",
        "\n",
        "# Tunix import verification\n",
        "print(\"\\n\ud83d\udd0d Tunix Import Verification:\")\n",
        "try:\n",
        "    import tunix\n",
        "    print(\"   \u2705 Tunix imported successfully\")\n",
        "    if hasattr(tunix, '__version__'):\n",
        "        print(f\"   Tunix version: {tunix.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"   \u274c Tunix import failed: {e}\")\n",
        "    print(\"   \ud83d\udca1 Solution: Use google-tunix>=0.1.0,<=0.1.5\")\n",
        "\n",
        "# Flax verification\n",
        "print(\"\\n\ud83d\udd0d Flax Verification:\")\n",
        "try:\n",
        "    import flax\n",
        "    print(f\"   \u2705 Flax imported successfully\")\n",
        "    print(f\"   Flax version: {flax.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"   \u274c Flax import failed: {e}\")\n",
        "    print(\"   \ufffd\ufffd Solution: Install flax==0.10.2\")\n",
        "\n",
        "# Assertions for validation\n",
        "print(\"\\n\ud83e\uddea Validation Assertions:\")\n",
        "try:\n",
        "    assert len(devices) >= 1, f\"Expected at least 1 device, got {len(devices)}\"\n",
        "    print(f\"   \u2705 Device count: {len(devices)} (expected 8 for TPU v2-8)\")\n",
        "    \n",
        "    if len(devices) > 0:\n",
        "        device_platform = devices[0].platform\n",
        "        if device_platform == 'tpu':\n",
        "            print(f\"   \u2705 Device type: TPU confirmed\")\n",
        "        else:\n",
        "            print(f\"   \u26a0\ufe0f Device type: {device_platform} (expected 'tpu')\")\n",
        "            print(\"   \ud83d\udca1 Hint: Set runtime to TPU: Runtime \u2192 Change runtime type \u2192 TPU\")\n",
        "        \n",
        "    print(\"   \u2705 All core imports successful\")\n",
        "except AssertionError as e:\n",
        "    print(f\"   \u274c Assertion failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udccb Phase 1: HBM (High Bandwidth Memory) Check\n",
        "print(\"=\"*60)\n",
        "print(\"\ud83d\udccb HBM MEMORY VISIBILITY CHECK\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "hbm_check_passed = False  # Will be set to True if successful\n",
        "\n",
        "try:\n",
        "    from tunix.sft import utils as tunix_utils\n",
        "    \n",
        "    print(\"\\n\ud83d\udd0d HBM Memory Stats:\")\n",
        "    if hasattr(tunix_utils, 'show_hbm_usage'):\n",
        "        tunix_utils.show_hbm_usage()\n",
        "        print(\"\\n   \u2705 HBM memory stats visible\")\n",
        "        hbm_check_passed = True\n",
        "    else:\n",
        "        print(\"   \u26a0\ufe0f show_hbm_usage() not available in this Tunix version\")\n",
        "        print(\"   This is informational only - training can proceed\")\n",
        "        hbm_check_passed = True  # Still passes as optional\n",
        "        \n",
        "except ImportError as e:\n",
        "    print(f\"   \u26a0\ufe0f Tunix SFT utils not available: {e}\")\n",
        "    print(\"   This is informational only - training can proceed\")\n",
        "    hbm_check_passed = True  # Still passes as optional\n",
        "except Exception as e:\n",
        "    print(f\"   \u26a0\ufe0f HBM check warning: {e}\")\n",
        "    print(\"   This is informational only - training can proceed\")\n",
        "    hbm_check_passed = True  # Still passes as optional\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udccb Phase 1: LoRA Adapter Initialization Test\n",
        "print(\"=\"*60)\n",
        "print(\"\ud83d\udccb LORA ADAPTER INITIALIZATION TEST\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Define LoRA configuration for testing\n",
        "lora_test_config = {\n",
        "    \"rank\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
        "    \"dropout\": 0.05,\n",
        "}\n",
        "\n",
        "print(\"\\n\ud83d\udd0d LoRA Configuration:\")\n",
        "for key, value in lora_test_config.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Test Tunix AutoModel access\n",
        "print(\"\\n\ud83d\udd0d Tunix AutoModel Access:\")\n",
        "try:\n",
        "    from tunix.models import automodel\n",
        "    print(\"   \u2705 Tunix AutoModel module accessible\")\n",
        "except ImportError as e:\n",
        "    print(f\"   \u26a0\ufe0f AutoModel import: {e}\")\n",
        "    print(\"   Note: This is optional - direct model loading still works\")\n",
        "\n",
        "# Test Gemma model access\n",
        "print(\"\\n\ud83d\udd0d Gemma Model Access:\")\n",
        "try:\n",
        "    from tunix.models.gemma3 import model as gemma_model\n",
        "    print(\"   \u2705 Gemma3 model module accessible\")\n",
        "except ImportError as e:\n",
        "    print(f\"   \u274c Gemma3 model import failed: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \ud83d\udccb Phase 1: Validation Summary\n",
        "import sys\n",
        "import jax\n",
        "import flax\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"\ud83d\udccb PHASE 1: COLAB TPU SMOKE TEST - VALIDATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Collect validation results\n",
        "validation_results = {}\n",
        "\n",
        "# TPU Runtime check\n",
        "try:\n",
        "    devices = jax.devices()\n",
        "    num_devices = len(devices)\n",
        "    if num_devices > 0:\n",
        "        device_type = devices[0].platform\n",
        "        validation_results['TPU Runtime (8 cores)'] = num_devices == 8\n",
        "        validation_results['TPU Device Type'] = device_type == 'tpu'\n",
        "    else:\n",
        "        validation_results['TPU Runtime (8 cores)'] = False\n",
        "        validation_results['TPU Device Type'] = False\n",
        "except Exception:\n",
        "    validation_results['TPU Runtime (8 cores)'] = False\n",
        "    validation_results['TPU Device Type'] = False\n",
        "\n",
        "# JAX version check\n",
        "try:\n",
        "    validation_results['JAX Version'] = jax.__version__ is not None\n",
        "except Exception:\n",
        "    validation_results['JAX Version'] = False\n",
        "\n",
        "# Tunix import check\n",
        "validation_results['Tunix Import'] = 'tunix' in sys.modules\n",
        "\n",
        "# Flax version check\n",
        "try:\n",
        "    validation_results['Flax Version'] = flax.__version__ is not None\n",
        "except Exception:\n",
        "    validation_results['Flax Version'] = False\n",
        "\n",
        "# HBM visibility - check if previous cell set a flag\n",
        "validation_results['HBM Visibility'] = globals().get('hbm_check_passed', True)  # Optional\n",
        "\n",
        "# LoRA config ready - check in globals\n",
        "validation_results['LoRA Config Ready'] = 'lora_test_config' in globals()\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\ud83d\udcca Validation Results:\")\n",
        "print(\"-\" * 40)\n",
        "for check, passed in validation_results.items():\n",
        "    status = '\u2705 PASS' if passed else '\u274c FAIL'\n",
        "    print(f\"   {status} - {check}\")\n",
        "\n",
        "# Summary\n",
        "all_passed = all(validation_results.values())\n",
        "critical_passed = all([\n",
        "    validation_results.get('JAX Version', False),\n",
        "    validation_results.get('Tunix Import', False),\n",
        "    validation_results.get('Flax Version', False),\n",
        "])\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if all_passed:\n",
        "    print(\"\ud83c\udf89 ALL CHECKS PASSED - READY FOR PHASE 2 TRAINING\")\n",
        "elif critical_passed:\n",
        "    print(\"\u26a0\ufe0f CORE CHECKS PASSED - Some optional checks failed\")\n",
        "    print(\"   Training can proceed, but review warnings above.\")\n",
        "else:\n",
        "    print(\"\u274c CRITICAL CHECKS FAILED - REVIEW ERRORS ABOVE\")\n",
        "    print(\"   Fix issues before proceeding to Phase 2.\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Cross-reference to troubleshooting\n",
        "print(\"\\n\ud83d\udcda Troubleshooting Reference:\")\n",
        "print(\"   See 'Troubleshooting Guide' section at end of notebook\")\n",
        "print(\"   GitHub Issues: https://github.com/clduab11/judicAIta/issues\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udccb Phase 1 Troubleshooting Quick Reference\n",
        "\n",
        "| Error | Cause | Solution |\n",
        "|-------|-------|----------|\n",
        "| `ModuleNotFoundError: No module named 'tunix'` | Wrong Tunix version | Use `>=0.1.0,<=0.1.5` |\n",
        "| JAX TPU initialization fails | Wrong JAX version | Use `jax[tpu]` with libtpu releases |\n",
        "| `RuntimeError: TPU not found` | Wrong Colab runtime | Set runtime to TPU |\n",
        "| Imports fail after install | Runtime not restarted | Restart runtime after Step 1 |\n",
        "| `jax_cuda12_plugin` warnings | Normal for Colab | Ignore - harmless for TPU |\n",
        "| Only 1 device detected | CPU/GPU runtime | Change to TPU runtime |\n",
        "\n",
        "**Phase 1 Success Criteria:**\n",
        "- \u2705 All 8 TPU cores detected\n",
        "- \u2705 Tunix/Flax/JAX imports successful  \n",
        "- \u2705 HBM memory stats visible (optional)\n",
        "- \u2705 LoRA adapter modules accessible\n",
        "\n",
        "**\u2192 Phase 2 can proceed when all critical checks pass**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DsZY3GlL1eF"
      },
      "source": [
        "## \ud83d\udd10 Step 3: Authenticate with Hugging Face\n",
        "\n",
        "Login to Hugging Face to download the Gemma model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6lw-SfPL1eF"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login, snapshot_download\n",
        "import os\n",
        "\n",
        "# Login to Hugging Face\n",
        "# You'll be prompted to enter your HF token\n",
        "# Get your token from: https://huggingface.co/settings/tokens\n",
        "print(\"Please enter your Hugging Face token:\")\n",
        "login()\n",
        "\n",
        "print(\"\\n\u2705 Authenticated with Hugging Face!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZb1Gs9nL1eF"
      },
      "source": [
        "## \ud83d\udce5 Step 4: Download Gemma 3-1B-IT Model\n",
        "\n",
        "Download the model files and initialize the tokenizer.\n",
        "\n",
        "**Note**: Using `gemma-3-1b-it` as it's the latest available Gemma instruction-tuned model. Update to `gemma-3-1b-it` if/when available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXYTtu15L1eF"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "\n",
        "# Download model\n",
        "MODEL_ID = \"google/gemma-3-1b-it\"  # Using gemma-3-1b-it as gemma-3-1b-it may not be available yet\n",
        "CACHE_DIR = \"./gemma_model_cache\"\n",
        "\n",
        "print(f\"Downloading {MODEL_ID}...\")\n",
        "model_path = snapshot_download(\n",
        "    repo_id=MODEL_ID,\n",
        "    cache_dir=CACHE_DIR,\n",
        "    local_dir=f\"{CACHE_DIR}/gemma\",\n",
        "    local_dir_use_symlinks=False\n",
        ")\n",
        "print(f\"\u2705 Model downloaded to: {model_path}\")\n",
        "\n",
        "# Initialize tokenizer\n",
        "print(\"\\nInitializing tokenizer...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "print(f\"\u2705 Tokenizer initialized\")\n",
        "print(f\"   Vocab size: {len(tokenizer)}\")\n",
        "print(f\"   Special tokens: {tokenizer.special_tokens_map}\")\n",
        "\n",
        "# Test tokenization\n",
        "test_text = \"What is the legal precedent for breach of contract?\"\n",
        "tokens = tokenizer(test_text, return_tensors=\"np\")\n",
        "print(f\"\\n\ud83d\udcdd Test tokenization:\")\n",
        "print(f\"   Input: {test_text}\")\n",
        "print(f\"   Token count: {len(tokens['input_ids'][0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usIGOshsL1eF"
      },
      "source": [
        "## \ud83d\udd27 Step 5: Create Preprocessing Function\n",
        "\n",
        "Gemma models don't have native system role support. We'll prepend the system prompt to the first user turn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sNu7HH0L1eF"
      },
      "outputs": [],
      "source": [
        "def preprocess_with_system_prompt(messages, system_prompt):\n",
        "    \"\"\"\n",
        "    Prepend system prompt to first user message.\n",
        "\n",
        "    Gemma doesn't support system role natively, so we merge it with\n",
        "    the first user turn as a workaround.\n",
        "\n",
        "    Args:\n",
        "        messages: List of message dicts with 'role' and 'content'\n",
        "        system_prompt: System instruction string\n",
        "\n",
        "    Returns:\n",
        "        Modified messages list with system prompt prepended\n",
        "    \"\"\"\n",
        "    if not messages:\n",
        "        return messages\n",
        "\n",
        "    processed = messages.copy()\n",
        "\n",
        "    # Find first user message\n",
        "    for i, msg in enumerate(processed):\n",
        "        if msg.get('role') == 'user':\n",
        "            # Prepend system prompt\n",
        "            original_content = msg['content']\n",
        "            processed[i]['content'] = f\"{system_prompt}\\n\\n{original_content}\"\n",
        "            break\n",
        "\n",
        "    return processed\n",
        "\n",
        "# Define system prompt for legal reasoning\n",
        "SYSTEM_PROMPT = \"\"\"You are a legal AI assistant. For each question, provide your analysis in this exact format:\n",
        "<reasoning>Your step-by-step legal reasoning here. Include relevant legal principles, precedents, and analysis. Aim for at least 100 tokens of detailed reasoning.</reasoning>\n",
        "<answer>Your final answer or conclusion here.</answer>\n",
        "\n",
        "Always use this XML format and ensure your reasoning is thorough and well-explained.\"\"\"\n",
        "\n",
        "# Test preprocessing\n",
        "test_messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Is a non-compete clause enforceable in California?\"}\n",
        "]\n",
        "processed = preprocess_with_system_prompt(test_messages, SYSTEM_PROMPT)\n",
        "print(\"\ud83d\udcdd Test preprocessing:\")\n",
        "print(f\"Original: {test_messages[0]['content'][:50]}...\")\n",
        "print(f\"\\nProcessed length: {len(processed[0]['content'])} chars\")\n",
        "print(f\"System prompt prepended: {'<reasoning>' in processed[0]['content']}\")\n",
        "print(\"\\n\u2705 Preprocessing function ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Y7D8ZDL1eF"
      },
      "source": [
        "## \ud83d\udcca Task 2: Prepare Training Dataset\n",
        "\n",
        "Create a dataset with XML-tagged reasoning format compatible with Tunix GRPO."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQC6uBQRL1eF"
      },
      "source": [
        "### JSONL Format Requirements\n",
        "\n",
        "Each training example must be a JSON object with:\n",
        "- `prompt`: The question or task\n",
        "- `ground_truth`: The correct answer for evaluation\n",
        "- `metadata` (optional): Additional info like task_id, difficulty, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-jmuHzQL1eG"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from typing import List, Dict, Any\n",
        "from datasets import load_dataset\n",
        "\n",
        "def prepare_dataset_for_tunix(examples: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Prepare dataset in Tunix-compatible JSONL format.\n",
        "\n",
        "    Args:\n",
        "        examples: List of dicts with 'question' and 'answer' fields\n",
        "\n",
        "    Returns:\n",
        "        List of dicts with 'prompt', 'ground_truth', and 'metadata'\n",
        "    \"\"\"\n",
        "    prepared = []\n",
        "\n",
        "    for idx, ex in enumerate(examples):\n",
        "        prepared.append({\n",
        "            \"prompt\": ex.get(\"question\", ex.get(\"prompt\", \"\")),\n",
        "            \"ground_truth\": ex.get(\"answer\", ex.get(\"ground_truth\", \"\")),\n",
        "            \"metadata\": {\n",
        "                \"example_id\": idx,\n",
        "                \"original_question\": ex.get(\"question\", \"\"),\n",
        "                \"task_type\": ex.get(\"task_type\", \"general_reasoning\")\n",
        "            }\n",
        "        })\n",
        "\n",
        "    return prepared\n",
        "\n",
        "print(\"\ud83d\udce5 Loading real legal data from HuggingFace (nguha/legalbench)...\")\n",
        "\n",
        "# Load subset: 'contract_qa' (Contract Law questions)\n",
        "try:\n",
        "    dataset = load_dataset(\"nguha/legalbench\", \"contract_qa\", split=\"train\")\n",
        "    print(f\"   Loaded {len(dataset)} examples from LegalBench (contract_qa)\")\n",
        "    \n",
        "    # Take first 100 examples for this demo/hackathon training\n",
        "    # (In full training, use more)\n",
        "    real_examples = []\n",
        "    for item in dataset.select(range(min(len(dataset), 100))):\n",
        "        real_examples.append({\n",
        "            \"question\": item[\"question\"],\n",
        "            \"answer\": item[\"answer\"], # LegalBench uses 'answer' usually yes/no or text\n",
        "            \"task_type\": \"contract_qa\"\n",
        "        })\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\u26a0\ufe0f Failed to load LegalBench: {e}\")\n",
        "    print(\"   Falling back to synthetic examples for demonstration.\")\n",
        "    real_examples = [\n",
        "        {\n",
        "            \"question\": \"Can an employer in California enforce a non-compete clause against a former employee?\",\n",
        "            \"answer\": \"No, non-compete clauses are generally unenforceable in California except in limited circumstances involving sale of business or dissolution of partnership.\",\n",
        "            \"task_type\": \"legal_qa\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What is the statute of limitations for filing a breach of contract claim?\",\n",
        "            \"answer\": \"The statute of limitations varies by jurisdiction. In many states, it is 4-6 years for written contracts and 2-3 years for oral contracts.\",\n",
        "            \"task_type\": \"legal_qa\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"Under what circumstances can a contract be voided for duress?\",\n",
        "            \"answer\": \"A contract can be voided for duress when one party was forced to enter the agreement through threats, violence, or other improper pressure that overcame their free will.\",\n",
        "            \"task_type\": \"legal_qa\"\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"What is required to establish an attorney-client privilege?\",\n",
        "            \"answer\": \"Attorney-client privilege requires: (1) an attorney-client relationship, (2) confidential communication, (3) made for the purpose of seeking or providing legal advice.\",\n",
        "            \"task_type\": \"legal_qa\"\n",
        "        },\n",
        "    ]\n",
        "\n",
        "# Prepare dataset\n",
        "prepared_dataset = prepare_dataset_for_tunix(real_examples)\n",
        "\n",
        "print(f\"\u2705 Prepared {len(prepared_dataset)} training examples\")\n",
        "print(f\"\\n\ud83d\udcdd Sample example:\")\n",
        "print(json.dumps(prepared_dataset[0], indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGaUPGu5L1eG"
      },
      "source": [
        "### Prompt Template with XML Format\n",
        "\n",
        "Create a template that formats prompts to expect XML-tagged reasoning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efXvIT8TL1eG"
      },
      "outputs": [],
      "source": [
        "def create_prompt_template(question: str, system_prompt: str = SYSTEM_PROMPT) -> str:\n",
        "    \"\"\"\n",
        "    Create a formatted prompt with XML output expectations.\n",
        "\n",
        "    Args:\n",
        "        question: The legal question to answer\n",
        "        system_prompt: System instructions for format\n",
        "\n",
        "    Returns:\n",
        "        Formatted prompt string\n",
        "    \"\"\"\n",
        "    template = f\"\"\"{system_prompt}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Response:\"\"\"\n",
        "    return template\n",
        "\n",
        "def validate_xml_format(response: str) -> bool:\n",
        "    \"\"\"\n",
        "    Validate that response contains proper XML tags.\n",
        "\n",
        "    Args:\n",
        "        response: Model generated response\n",
        "\n",
        "    Returns:\n",
        "        True if valid XML format, False otherwise\n",
        "    \"\"\"\n",
        "    # Check for both opening and closing tags\n",
        "    has_reasoning = '<reasoning>' in response and '</reasoning>' in response\n",
        "    has_answer = '<answer>' in response and '</answer>' in response\n",
        "\n",
        "    return has_reasoning and has_answer\n",
        "\n",
        "# Apply template to all examples\n",
        "templated_prompts = []\n",
        "for example in prepared_dataset:\n",
        "    templated = {\n",
        "        \"prompt\": create_prompt_template(example[\"prompt\"]),\n",
        "        \"ground_truth\": example[\"ground_truth\"],\n",
        "        \"metadata\": example[\"metadata\"],\n",
        "        \"original_prompt\": example[\"prompt\"]\n",
        "    }\n",
        "    templated_prompts.append(templated)\n",
        "\n",
        "print(f\"\u2705 Created {len(templated_prompts)} templated prompts\")\n",
        "print(f\"\\n\ud83d\udcdd Sample templated prompt (first 300 chars):\")\n",
        "print(templated_prompts[0][\"prompt\"][:300])\n",
        "print(\"...\")\n",
        "\n",
        "# Test validation\n",
        "test_valid = \"<reasoning>This is reasoning</reasoning><answer>This is answer</answer>\"\n",
        "test_invalid = \"This is just text without tags\"\n",
        "print(f\"\\n\u2705 Validation test:\")\n",
        "print(f\"   Valid format: {validate_xml_format(test_valid)}\")\n",
        "print(f\"   Invalid format: {validate_xml_format(test_invalid)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgkWNF_EL1eG"
      },
      "source": [
        "### Tokenization and Batching\n",
        "\n",
        "Tokenize prompts and prepare batches for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AInVAlZZL1eG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from typing import List, Dict\n",
        "\n",
        "# Set maximum prompt length\n",
        "MAX_PROMPT_LENGTH = 512  # Adjust based on your needs (512 or 1024)\n",
        "MAX_RESPONSE_LENGTH = 512\n",
        "\n",
        "def tokenize_prompts(prompts: List[str], tokenizer, max_length: int = MAX_PROMPT_LENGTH):\n",
        "    \"\"\"\n",
        "    Tokenize prompts with padding and truncation.\n",
        "\n",
        "    Args:\n",
        "        prompts: List of prompt strings\n",
        "        tokenizer: HuggingFace tokenizer\n",
        "        max_length: Maximum token length\n",
        "\n",
        "    Returns:\n",
        "        Dict with input_ids and attention_mask\n",
        "    \"\"\"\n",
        "    tokenized = tokenizer(\n",
        "        prompts,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        return_tensors=\"np\"\n",
        "    )\n",
        "    return tokenized\n",
        "\n",
        "def create_training_batches(dataset: List[Dict], batch_size: int = 4):\n",
        "    \"\"\"\n",
        "    Create batches from dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset: List of training examples\n",
        "        batch_size: Number of examples per batch\n",
        "\n",
        "    Returns:\n",
        "        List of batches, each batch is a list of examples\n",
        "    \"\"\"\n",
        "    batches = []\n",
        "    for i in range(0, len(dataset), batch_size):\n",
        "        batch = dataset[i:i + batch_size]\n",
        "        batches.append(batch)\n",
        "    return batches\n",
        "\n",
        "# Tokenize all prompts\n",
        "all_prompts = [ex[\"prompt\"] for ex in templated_prompts]\n",
        "tokenized_prompts = tokenize_prompts(all_prompts, tokenizer, MAX_PROMPT_LENGTH)\n",
        "\n",
        "print(f\"\u2705 Tokenized {len(all_prompts)} prompts\")\n",
        "print(f\"   Max length: {MAX_PROMPT_LENGTH} tokens\")\n",
        "print(f\"   Shape: {tokenized_prompts['input_ids'].shape}\")\n",
        "\n",
        "# Create final dataset for training\n",
        "training_dataset = []\n",
        "for i, ex in enumerate(templated_prompts):\n",
        "    training_dataset.append({\n",
        "        \"prompt\": ex[\"prompt\"],\n",
        "        \"prompt_tokens\": tokenized_prompts['input_ids'][i],\n",
        "        \"attention_mask\": tokenized_prompts['attention_mask'][i],\n",
        "        \"ground_truth\": ex[\"ground_truth\"],\n",
        "        \"metadata\": ex[\"metadata\"]\n",
        "    })\n",
        "\n",
        "print(f\"\\n\u2705 Final training dataset: {len(training_dataset)} examples\")\n",
        "print(f\"   Each example has: {list(training_dataset[0].keys())}\")\n",
        "\n",
        "# Validate dataset format\n",
        "required_fields = [\"prompt\", \"ground_truth\", \"metadata\"]\n",
        "all_valid = all(all(field in ex for field in required_fields) for ex in training_dataset)\n",
        "print(f\"\\n\u2705 Dataset validation: {'PASSED' if all_valid else 'FAILED'}\")\n",
        "\n",
        "if not all_valid:\n",
        "    print(\"\u274c Some examples missing required fields!\")\n",
        "else:\n",
        "    print(\"   All examples have required fields: prompt, ground_truth, metadata\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMG3okLhL1eG"
      },
      "source": [
        "## \ud83c\udfaf Task 3: Implement Custom Reward Function\n",
        "\n",
        "Create a competition-compliant reward function that scores:\n",
        "1. **Answer Correctness** (35%): Match with ground truth (exact or Jaccard)\n",
        "2. **Legal Accuracy** (25%): Valid legal citation patterns (e.g., U.S.C., v., \u00a7)\n",
        "3. **Reasoning Coherence** (25%): Structural integrity and lack of repetition\n",
        "4. **Format Compliance** (10%): Proper XML `<reasoning>` and `<answer>` tags\n",
        "5. **Reasoning Length** (5%): Encouraging detailed analysis (>150 tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1NTvRVUL1eG"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Tuple, Optional\n",
        "\n",
        "def extract_xml_content(response: str) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"\n",
        "    Extract content from <reasoning> and <answer> XML tags.\n",
        "\n",
        "    Args:\n",
        "        response: Model-generated response string\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (reasoning_content, answer_content)\n",
        "        Returns (None, None) if tags are malformed or missing\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract reasoning\n",
        "        reasoning_match = re.search(r'<reasoning>(.*?)</reasoning>', response, re.DOTALL)\n",
        "        reasoning = reasoning_match.group(1).strip() if reasoning_match else None\n",
        "\n",
        "        # Extract answer\n",
        "        answer_match = re.search(r'<answer>(.*?)</answer>', response, re.DOTALL)\n",
        "        answer = answer_match.group(1).strip() if answer_match else None\n",
        "\n",
        "        return reasoning, answer\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error extracting XML content: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Test extraction with edge cases\n",
        "test_cases = [\n",
        "    # Valid case\n",
        "    \"<reasoning>Step by step analysis here</reasoning><answer>Final answer</answer>\",\n",
        "    # Missing tags\n",
        "    \"Just plain text without tags\",\n",
        "    # Partial tags\n",
        "    \"<reasoning>Incomplete reasoning\",\n",
        "    # Nested content\n",
        "    \"<reasoning>Analysis with <term>nested</term> content</reasoning><answer>Yes</answer>\",\n",
        "    # Multi-line\n",
        "    \"\"\"<reasoning>\n",
        "Line 1 of reasoning\n",
        "Line 2 of reasoning\n",
        "</reasoning>\n",
        "<answer>Final answer</answer>\"\"\"\n",
        "]\n",
        "\n",
        "print(\"\ud83e\uddea Testing XML extraction:\")\n",
        "for i, test in enumerate(test_cases, 1):\n",
        "    reasoning, answer = extract_xml_content(test)\n",
        "    print(f\"\\nTest {i}:\")\n",
        "    print(f\"  Reasoning found: {reasoning is not None}\")\n",
        "    print(f\"  Answer found: {answer is not None}\")\n",
        "    if reasoning:\n",
        "        print(f\"  Reasoning preview: {reasoning[:50]}...\")\n",
        "    if answer:\n",
        "        print(f\"  Answer: {answer}\")\n",
        "\n",
        "print(\"\\n\u2705 XML extraction function tested with edge cases\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzinMYgVL1eH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Tuple, Optional, List, Dict\n",
        "\n",
        "def extract_xml_content(response: str) -> Tuple[Optional[str], Optional[str]]:\n",
        "    \"\"\"\n",
        "    Extract content from <reasoning> and <answer> XML tags.\n",
        "\n",
        "    Args:\n",
        "        response: Model-generated response string\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (reasoning_content, answer_content)\n",
        "        Returns (None, None) if tags are malformed or missing\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract reasoning\n",
        "        reasoning_match = re.search(r'<reasoning>(.*?)</reasoning>', response, re.DOTALL)\n",
        "        reasoning = reasoning_match.group(1).strip() if reasoning_match else None\n",
        "\n",
        "        # Extract answer\n",
        "        answer_match = re.search(r'<answer>(.*?)</answer>', response, re.DOTALL)\n",
        "        answer = answer_match.group(1).strip() if answer_match else None\n",
        "\n",
        "        return reasoning, answer\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error extracting XML content: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def compute_format_reward(response: str) -> float:\n",
        "    \"\"\"\n",
        "    Reward for valid XML format (10% weight).\n",
        "    \"\"\"\n",
        "    reasoning, answer = extract_xml_content(response)\n",
        "\n",
        "    # Check both tags present and have content\n",
        "    if reasoning is not None and answer is not None:\n",
        "        if len(reasoning.strip()) > 0 and len(answer.strip()) > 0:\n",
        "            return 1.0\n",
        "\n",
        "    return 0.0\n",
        "\n",
        "def compute_legal_accuracy_reward(response: str, query_context: str = \"\") -> float:\n",
        "    \"\"\"\n",
        "    Reward for using proper legal citation format (25% weight).\n",
        "    Checks for presence of standard legal citation patterns.\n",
        "    \"\"\"\n",
        "    reasoning, _ = extract_xml_content(response)\n",
        "    if not reasoning:\n",
        "        return 0.0\n",
        "        \n",
        "    # Basic legal citation patterns\n",
        "    patterns = [\n",
        "        r'\\d+\\s+U\\.S\\.C\\.',       # US Code (e.g., 17 U.S.C.)\n",
        "        r'v\\.',                   # Case names (Plaintiff v. Defendant)\n",
        "        r'\u00a7',                     # Section symbol\n",
        "        r'Article\\s+[IVX]+',      # Articles\n",
        "        r'See\\s+also',            # Legal writing style\n",
        "        r'Id\\.',                  # Citation shorthand\n",
        "        r'Cir\\.',                 # Circuit courts\n",
        "        r'Cal\\.',                 # California codes (example)\n",
        "        r'Rev\\.',                 # Review\n",
        "    ]\n",
        "    \n",
        "    matches = 0\n",
        "    for pattern in patterns:\n",
        "        if re.search(pattern, reasoning, re.IGNORECASE):\n",
        "            matches += 1\n",
        "            \n",
        "    # Cap at 1.0 \n",
        "    return min(1.0, max(0.2, matches * 0.5) if matches > 0 else 0.0)\n",
        "\n",
        "def compute_reasoning_coherence_reward(response: str) -> float:\n",
        "    \"\"\"\n",
        "    Reward for coherence (25% weight).\n",
        "    Penalizes repetition and rewards structure.\n",
        "    \"\"\"\n",
        "    reasoning, _ = extract_xml_content(response)\n",
        "    if not reasoning:\n",
        "        return 0.0\n",
        "        \n",
        "    # 1. Repetition penalty\n",
        "    sentences = [s.strip() for s in reasoning.split('.') if len(s.strip()) > 10]\n",
        "    if not sentences:\n",
        "        return 0.0\n",
        "        \n",
        "    unique_sentences = set(sentences)\n",
        "    repetition_ratio = len(unique_sentences) / len(sentences)\n",
        "    \n",
        "    # 2. Structure heuristic\n",
        "    has_paragraphs = '\\n\\n' in reasoning\n",
        "    transitions = ['Therefore', 'However', 'Furthermore', 'Accordingly', 'Thus']\n",
        "    has_transitions = any(t in reasoning for t in transitions)\n",
        "    \n",
        "    # Combine \n",
        "    score = repetition_ratio * 0.7 + (0.15 if has_paragraphs else 0.0) + (0.15 if has_transitions else 0.0)\n",
        "    return min(1.0, score)\n",
        "\n",
        "def compute_reasoning_length_penalty(response: str, tokenizer, min_tokens: int = 150) -> float:\n",
        "    \"\"\"\n",
        "    Reward for reasoning length (5% weight).\n",
        "    Targeting ~150+ tokens for detailed analysis.\n",
        "    \"\"\"\n",
        "    reasoning, _ = extract_xml_content(response)\n",
        "    if not reasoning:\n",
        "        return 0.0\n",
        "        \n",
        "    # Tokenize reasoning to count tokens\n",
        "    tokens = tokenizer(reasoning, return_tensors=\"np\")[\"input_ids\"]\n",
        "    num_tokens = len(tokens[0])\n",
        "    \n",
        "    # Return 1.0 if meets threshold, otherwise proportional\n",
        "    if num_tokens >= min_tokens:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return num_tokens / min_tokens\n",
        "\n",
        "def compute_answer_correctness_reward(response: str, ground_truth: str, tokenizer) -> float:\n",
        "    \"\"\"\n",
        "    Reward based on answer correctness (35% weight).\n",
        "    \"\"\"\n",
        "    _, answer = extract_xml_content(response)\n",
        "\n",
        "    if answer is None:\n",
        "        return 0.0\n",
        "\n",
        "    # Normalize for comparison\n",
        "    answer_norm = answer.lower().strip()\n",
        "    ground_truth_norm = ground_truth.lower().strip()\n",
        "\n",
        "    # Check exact match\n",
        "    if answer_norm == ground_truth_norm:\n",
        "        return 1.0\n",
        "\n",
        "    # Tokenize both for overlap calculation\n",
        "    answer_tokens = set(tokenizer.tokenize(answer_norm))\n",
        "    truth_tokens = set(tokenizer.tokenize(ground_truth_norm))\n",
        "\n",
        "    # Calculate Jaccard similarity\n",
        "    if len(answer_tokens) == 0 or len(truth_tokens) == 0:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = len(answer_tokens & truth_tokens)\n",
        "    union = len(answer_tokens | truth_tokens)\n",
        "\n",
        "    jaccard = intersection / union if union > 0 else 0.0\n",
        "\n",
        "    return jaccard\n",
        "\n",
        "print(\"\u2705 Reward component functions defined:\")\n",
        "print(\"   - compute_format_reward (10%)\")\n",
        "print(\"   - compute_legal_accuracy_reward (25%)\")\n",
        "print(\"   - compute_reasoning_coherence_reward (25%)\")\n",
        "print(\"   - compute_answer_correctness_reward (35%)\")\n",
        "print(\"   - compute_reasoning_length_penalty (5%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTDgkt1pL1eH"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "def composite_reward_function(\n",
        "    prompts: List[str],\n",
        "    completions: List[str],\n",
        "    metadata: List[Dict],\n",
        "    tokenizer\n",
        ") -> List[float]:\n",
        "    \"\"\"\n",
        "    Competition-compliant composite reward function.\n",
        "    \n",
        "    Weights:\n",
        "    - Answer Correctness: 35%\n",
        "    - Reasoning Coherence: 25%\n",
        "    - Legal Accuracy: 25%\n",
        "    - Format Compliance: 10%\n",
        "    - Length Penalty: 5%\n",
        "    \"\"\"\n",
        "    # Competition Weights\n",
        "    W_CORRECTNESS = 0.35\n",
        "    W_COHERENCE = 0.25\n",
        "    W_LEGAL = 0.25\n",
        "    W_FORMAT = 0.10\n",
        "    W_LENGTH = 0.05\n",
        "    \n",
        "    rewards = []\n",
        "    \n",
        "    for i, (prompt, completion, meta) in enumerate(zip(prompts, completions, metadata)):\n",
        "        # Compute each reward component\n",
        "        r_format = compute_format_reward(completion)\n",
        "        r_correctness = compute_answer_correctness_reward(completion, meta.get(\"ground_truth\", \"\"), tokenizer)\n",
        "        r_coherence = compute_reasoning_coherence_reward(completion)\n",
        "        r_legal = compute_legal_accuracy_reward(completion)\n",
        "        r_length = compute_reasoning_length_penalty(completion, tokenizer)\n",
        "        \n",
        "        # Aggregate rewards\n",
        "        total_reward = (\n",
        "            W_CORRECTNESS * r_correctness +\n",
        "            W_COHERENCE * r_coherence +\n",
        "            W_LEGAL * r_legal +\n",
        "            W_FORMAT * r_format +\n",
        "            W_LENGTH * r_length\n",
        "        )\n",
        "        \n",
        "        rewards.append(total_reward)\n",
        "        \n",
        "        # Log breakdown for first few examples\n",
        "        if i < 3:\n",
        "            print(f\"\\n\ud83d\udcca Example {i} reward breakdown:\")\n",
        "            print(f\"   Correctness ({W_CORRECTNESS}): {r_correctness:.2f}\")\n",
        "            print(f\"   Coherence ({W_COHERENCE}): {r_coherence:.2f}\")\n",
        "            print(f\"   Legal ({W_LEGAL}): {r_legal:.2f}\")\n",
        "            print(f\"   Format ({W_FORMAT}): {r_format:.2f}\")\n",
        "            print(f\"   Length ({W_LENGTH}): {r_length:.2f}\")\n",
        "            print(f\"   TOTAL: {total_reward:.2f}\")\n",
        "            \n",
        "    return rewards\n",
        "\n",
        "\n",
        "def tunix_reward_wrapper(prompts: List[str], outputs: List[str]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Wrapper function matching Tunix RewardFn signature.\n",
        "    \"\"\"\n",
        "    # Build metadata from training dataset\n",
        "    metadata = []\n",
        "    for prompt in prompts:\n",
        "        # Find matching ground truth from training_dataset\n",
        "        found = False\n",
        "        for example in training_dataset:\n",
        "            if example[\"prompt\"] in prompt or prompt in example[\"prompt\"]:\n",
        "                metadata.append({\"ground_truth\": example[\"ground_truth\"]})\n",
        "                found = True\n",
        "                break\n",
        "        if not found:\n",
        "            metadata.append({\"ground_truth\": \"\"})\n",
        "\n",
        "    return composite_reward_function(prompts, outputs, metadata, tokenizer)\n",
        "\n",
        "# Test reward function\n",
        "print(\"\ud83e\uddea Testing reward function...\")\n",
        "test_prompts = [\"Test question\"]\n",
        "test_completions = [\n",
        "    \"<reasoning>This is a detailed legal analysis with sufficient tokens to explain the reasoning behind the answer. We consider precedent, statutory law (17 U.S.C.), and policy implications. Furthermore, the court in Smith v. Jones held that detailed analysis is required.</reasoning><answer>Yes, it is enforceable.</answer>\"\n",
        "]\n",
        "test_metadata = [{\"ground_truth\": \"Yes, it is enforceable.\"}]\n",
        "\n",
        "test_rewards = composite_reward_function(test_prompts, test_completions, test_metadata, tokenizer)\n",
        "print(f\"\\n\u2705 Reward function test complete\")\n",
        "print(f\"   Test reward: {test_rewards[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLq5dwQuL1eH"
      },
      "outputs": [],
      "source": [
        "# Verify Tunix installation before training setup\n",
        "print(\"\ud83d\udce6 Verifying Tunix installation...\")\n",
        "\n",
        "import sys\n",
        "\n",
        "# Check Tunix availability\n",
        "try:\n",
        "    import tunix\n",
        "    print(f\"\u2705 Tunix installed: {tunix.__version__ if hasattr(tunix, '__version__') else 'version unknown'}\")\n",
        "except ImportError as e:\n",
        "    print(f\"\u274c Tunix not available: {e}\")\n",
        "    print(\"\\n\ud83d\udd27 To install Tunix:\")\n",
        "    print(\"   !pip install 'google-tunix[tpu]>=0.1.0'\")\n",
        "    print(\"   Then restart runtime and run this cell again.\")\n",
        "    raise\n",
        "\n",
        "# Check required submodules\n",
        "modules_to_check = [\n",
        "    (\"tunix.rl.grpo.grpo_learner\", \"GRPOConfig, GRPOLearner\"),\n",
        "    (\"tunix.rl.rl_cluster\", \"RLCluster\"),\n",
        "    (\"tunix.models.gemma\", \"GemmaForCausalLM\"),\n",
        "]\n",
        "\n",
        "print(\"\\n\ud83d\udccb Checking Tunix submodules:\")\n",
        "all_available = True\n",
        "for module_path, expected_exports in modules_to_check:\n",
        "    try:\n",
        "        module = __import__(module_path, fromlist=[''])\n",
        "        print(f\"   \u2705 {module_path}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"   \u274c {module_path}: {e}\")\n",
        "        all_available = False\n",
        "\n",
        "if all_available:\n",
        "    print(\"\\n\u2705 All Tunix modules available!\")\n",
        "    print(\"\\n\ud83d\udca1 Note: LoRA is configured through hyperparameters (rank, alpha) - no separate PEFT module needed.\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f Some modules not available. Check Tunix version and installation.\")\n",
        "    print(\"   The training cells may need adaptation for your Tunix version.\")\n",
        "\n",
        "# Check JAX backend\n",
        "print(\"\\n\ud83d\udcca JAX Backend Status:\")\n",
        "import jax\n",
        "print(f\"   JAX version: {jax.__version__}\")\n",
        "print(f\"   Backend: {jax.default_backend()}\")\n",
        "print(f\"   Devices: {jax.device_count()} ({jax.devices()[0].platform if jax.devices() else 'none'})\")\n",
        "\n",
        "print(\"\\n\u2705 Environment verified - ready for training setup!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_MODf-BL1eH"
      },
      "source": [
        "## \ud83d\ude80 Task 4: Configure and Execute GRPO Training\n",
        "\n",
        "Set up LoRA adapters and run GRPO training on TPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RxEzBSLL1eH"
      },
      "outputs": [],
      "source": [
        "# LoRA Hyperparameters for parameter-efficient fine-tuning\n",
        "LORA_CONFIG = {\n",
        "    \"rank\": 16,           # LoRA rank (16 or 32 recommended)\n",
        "    \"alpha\": 32,          # LoRA alpha (typically 2x rank)\n",
        "    \"dropout\": 0.05,      # LoRA dropout for regularization\n",
        "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Attention layers\n",
        "}\n",
        "\n",
        "# GRPO Configuration matching Tunix GRPOConfig parameters\n",
        "# Reference: https://tunix.readthedocs.io/en/latest/api/grpo.html\n",
        "GRPO_CONFIG = {\n",
        "    # Rollout settings\n",
        "    \"num_generations\": 4,           # Number of response samples per prompt for GRPO\n",
        "    \"max_tokens_to_generate\": 512,  # Maximum tokens for rollout generation\n",
        "\n",
        "    # GRPO algorithm hyperparameters\n",
        "    \"beta\": 0.04,                   # KL penalty coefficient (prevents policy divergence)\n",
        "    \"epsilon\": 0.2,                 # PPO-style clipping parameter\n",
        "\n",
        "    # Training settings\n",
        "    \"learning_rate\": 1e-5,          # Learning rate for LoRA parameters\n",
        "    \"batch_size\": 4,                # Batch size per TPU core (adjust for memory)\n",
        "    \"num_iterations\": 2,            # Number of training epochs/iterations\n",
        "\n",
        "    # Evaluation and checkpointing\n",
        "    \"eval_every_n_steps\": 50,       # Evaluate model every N steps\n",
        "    \"checkpoint_every_n_steps\": 100, # Save checkpoint every N steps\n",
        "}\n",
        "\n",
        "# Training configuration for RLCluster\n",
        "TRAINING_CONFIG = {\n",
        "    \"warmup_steps\": 10,             # Learning rate warmup steps\n",
        "    \"weight_decay\": 0.01,           # Weight decay for regularization\n",
        "    \"max_grad_norm\": 1.0,           # Gradient clipping threshold\n",
        "    \"log_every_n_steps\": 10,        # Log metrics every N steps\n",
        "}\n",
        "\n",
        "print(\"\u2705 Configuration defined:\")\n",
        "print(\"\\n\ud83d\udd27 LoRA Configuration:\")\n",
        "for k, v in LORA_CONFIG.items():\n",
        "    print(f\"   {k}: {v}\")\n",
        "print(\"\\n\ud83c\udfaf GRPO Configuration:\")\n",
        "for k, v in GRPO_CONFIG.items():\n",
        "    print(f\"   {k}: {v}\")\n",
        "print(\"\\n\ud83d\udcca Training Configuration:\")\n",
        "for k, v in TRAINING_CONFIG.items():\n",
        "    print(f\"   {k}: {v}\")\n",
        "\n",
        "print(\"\\n\ud83d\udca1 Hyperparameter Rationale:\")\n",
        "print(\"   - LoRA rank=16: Balance between capacity and memory efficiency\")\n",
        "print(\"   - num_generations=4: Standard for GRPO variance reduction\")\n",
        "print(\"   - beta=0.04: Conservative KL penalty to prevent policy divergence\")\n",
        "print(\"   - learning_rate=1e-5: Safe starting point for LoRA fine-tuning\")\n",
        "print(\"   - max_tokens_to_generate=512: Sufficient for detailed legal reasoning\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziCWkm-PL1eH"
      },
      "source": [
        "### \ud83d\udd27 Initialize Training Components\n",
        "\n",
        "This section sets up the Tunix GRPO training infrastructure:\n",
        "\n",
        "1. **Import Tunix modules**: GRPOConfig, GRPOLearner, RLCluster\n",
        "2. **Load and configure models**: Actor (trainable) and Reference (frozen) policies\n",
        "3. **Setup TPU mesh**: Configure sharding for distributed training\n",
        "4. **Initialize learner**: Create GRPOLearner with reward function\n",
        "\n",
        "**Prerequisites**:\n",
        "- TPU runtime initialized (verified in Step 2)\n",
        "- Model downloaded (completed in Step 4)\n",
        "- Reward function defined (completed above)\n",
        "- Training dataset prepared (completed above)\n",
        "\n",
        "**Documentation**:\n",
        "- [Tunix GRPO Guide](https://tunix.readthedocs.io/en/latest/tutorials/grpo.html)\n",
        "- [Official GRPO Gemma Example](https://github.com/google/tunix/tree/main/examples/grpo_gemma)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9bHhh9kL1eH"
      },
      "outputs": [],
      "source": [
        "# Import Tunix GRPO modules\n",
        "print(\"\ud83d\udce6 Importing Tunix modules...\")\n",
        "\n",
        "try:\n",
        "    from tunix.rl.grpo.grpo_learner import GRPOConfig, GRPOLearner\n",
        "    from tunix.rl import rl_cluster as rl_cluster_lib\n",
        "    from tunix.rl.rollout import base_rollout\n",
        "    from tunix.models.gemma3 import model as gemma_lib\n",
        "    print(\"\u2705 Tunix modules imported successfully!\")\n",
        "except ImportError as e:\n",
        "    print(f\"\u274c Tunix import failed: {e}\")\n",
        "    print(\"\\n\ud83d\udd27 Troubleshooting:\")\n",
        "    print(\"   1. Verify Tunix is installed: pip install git+https://github.com/google/tunix\")\n",
        "    print(\"   2. Restart runtime after installation\")\n",
        "    print(\"   3. Check Tunix version compatibility\")\n",
        "    raise\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.sharding import Mesh, NamedSharding, PartitionSpec\n",
        "import os\n",
        "\n",
        "# Create checkpoint directories\n",
        "CHECKPOINT_DIR = \"./checkpoints\"\n",
        "FINAL_DIR = \"./final_checkpoint\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\u2705 Checkpoint directories created:\")\n",
        "print(f\"   Intermediate: {CHECKPOINT_DIR}\")\n",
        "print(f\"   Final: {FINAL_DIR}\")\n",
        "\n",
        "# Setup TPU mesh for distributed training\n",
        "print(\"\\n\ud83d\udd27 Setting up TPU mesh...\")\n",
        "devices = jax.devices()\n",
        "num_devices = len(devices)\n",
        "\n",
        "# Create 1D mesh for data parallelism across TPU cores\n",
        "mesh = Mesh(devices, axis_names=(\"data\",))\n",
        "print(f\"\u2705 TPU mesh created with {num_devices} devices\")\n",
        "print(f\"   Mesh shape: {mesh.shape}\")\n",
        "print(f\"   Axis names: {mesh.axis_names}\")\n",
        "\n",
        "# Load Gemma model for GRPO training\n",
        "print(\"\\n\ud83d\udce5 Loading Gemma model for GRPO...\")\n",
        "\n",
        "# Create model configuration\n",
        "model_config = gemma_lib.GemmaConfig.from_pretrained(model_path)\n",
        "print(f\"   Model config loaded: {type(model_config).__name__}\")\n",
        "\n",
        "# Initialize actor model (trainable policy with LoRA)\n",
        "print(\"\\n\ud83c\udfad Initializing actor model (trainable)...\")\n",
        "# LoRA is configured through hyperparameters passed to the model or training config\n",
        "# Following Google's official GRPO examples - LoRA params are applied during training\n",
        "actor_model = gemma_lib.GemmaForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    dtype=jnp.bfloat16,  # Use bfloat16 for TPU efficiency\n",
        "    # LoRA hyperparameters are used by Tunix's native LoRA support\n",
        "    lora_rank=LORA_CONFIG[\"rank\"],\n",
        "    lora_alpha=LORA_CONFIG[\"alpha\"],\n",
        ")\n",
        "print(f\"   LoRA configured: rank={LORA_CONFIG['rank']}, alpha={LORA_CONFIG['alpha']}\")\n",
        "\n",
        "# Initialize reference model (frozen copy for KL penalty)\n",
        "print(\"\\n\ud83d\udccb Initializing reference model (frozen)...\")\n",
        "reference_model = gemma_lib.GemmaForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    dtype=jnp.bfloat16,\n",
        ")\n",
        "# Reference model parameters are frozen (no gradients)\n",
        "print(\"   Reference model loaded (frozen for KL divergence)\")\n",
        "\n",
        "print(\"\\n\u2705 Models initialized successfully!\")\n",
        "print(f\"   Actor model: LoRA-adapted, trainable\")\n",
        "print(f\"   Reference model: Frozen for KL penalty calculation\")\n",
        "\n",
        "# Create RLCluster configuration\n",
        "print(\"\\n\ud83d\udd27 Creating RLCluster...\")\n",
        "\n",
        "# Define sharding specs for model parallelism\n",
        "data_sharding = NamedSharding(mesh, PartitionSpec(\"data\"))\n",
        "\n",
        "# Create RLCluster with actor and reference models\n",
        "rl_cluster = rl_cluster_lib.RLCluster(\n",
        "    actor_model=actor_model,\n",
        "    reference_model=reference_model,\n",
        "    tokenizer=tokenizer,\n",
        "    mesh=mesh,\n",
        "    data_sharding=data_sharding,\n",
        ")\n",
        "print(\"\u2705 RLCluster created successfully!\")\n",
        "\n",
        "# Create GRPO configuration\n",
        "print(\"\\n\ud83c\udfaf Creating GRPOConfig...\")\n",
        "grpo_config = GRPOConfig(\n",
        "    num_generations=GRPO_CONFIG[\"num_generations\"],\n",
        "    max_tokens_to_generate=GRPO_CONFIG[\"max_tokens_to_generate\"],\n",
        "    beta=GRPO_CONFIG[\"beta\"],\n",
        "    epsilon=GRPO_CONFIG[\"epsilon\"],\n",
        "    learning_rate=GRPO_CONFIG[\"learning_rate\"],\n",
        "    warmup_steps=TRAINING_CONFIG[\"warmup_steps\"],\n",
        "    weight_decay=TRAINING_CONFIG[\"weight_decay\"],\n",
        "    max_grad_norm=TRAINING_CONFIG[\"max_grad_norm\"],\n",
        ")\n",
        "print(f\"\u2705 GRPOConfig created:\")\n",
        "print(f\"   num_generations: {grpo_config.num_generations}\")\n",
        "print(f\"   max_tokens_to_generate: {grpo_config.max_tokens_to_generate}\")\n",
        "print(f\"   beta (KL penalty): {grpo_config.beta}\")\n",
        "print(f\"   learning_rate: {grpo_config.learning_rate}\")\n",
        "\n",
        "# Initialize GRPO Learner\n",
        "print(\"\\n\ud83c\udf93 Initializing GRPOLearner...\")\n",
        "grpo_learner = GRPOLearner(\n",
        "    rl_cluster=rl_cluster,\n",
        "    algo_config=grpo_config,\n",
        "    reward_fns=[tunix_reward_wrapper],  # Use our wrapped reward function\n",
        ")\n",
        "print(\"\u2705 GRPOLearner initialized!\")\n",
        "print(\"   Reward function: tunix_reward_wrapper (composite XML/length/correctness)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\u2705 TRAINING SETUP COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nReady to execute GRPO training loop in the next cell.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqVM2k-LL1eH"
      },
      "outputs": [],
      "source": [
        "# Execute GRPO Training\n",
        "print(\"\ud83c\udfaf Starting GRPO Training...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Prepare training dataset in Tunix format\n",
        "print(\"\\n\ud83d\udcca Preparing training data...\")\n",
        "train_prompts = [ex[\"prompt\"] for ex in training_dataset]\n",
        "print(f\"   Training examples: {len(train_prompts)}\")\n",
        "\n",
        "# Training configuration\n",
        "num_iterations = GRPO_CONFIG[\"num_iterations\"]\n",
        "batch_size = GRPO_CONFIG[\"batch_size\"]\n",
        "eval_every = GRPO_CONFIG[\"eval_every_n_steps\"]\n",
        "checkpoint_every = GRPO_CONFIG[\"checkpoint_every_n_steps\"]\n",
        "log_every = TRAINING_CONFIG[\"log_every_n_steps\"]\n",
        "\n",
        "print(f\"\\n\ud83d\udccb Training Configuration:\")\n",
        "print(f\"   Iterations: {num_iterations}\")\n",
        "print(f\"   Batch size: {batch_size}\")\n",
        "print(f\"   Eval every: {eval_every} steps\")\n",
        "print(f\"   Checkpoint every: {checkpoint_every} steps\")\n",
        "\n",
        "# Training metrics storage\n",
        "training_metrics = {\n",
        "    \"losses\": [],\n",
        "    \"rewards\": [],\n",
        "    \"kl_divergences\": [],\n",
        "    \"steps\": [],\n",
        "}\n",
        "\n",
        "# Execute training\n",
        "start_time = time.time()\n",
        "global_step = 0\n",
        "\n",
        "try:\n",
        "    with mesh:\n",
        "        for iteration in range(num_iterations):\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"\ud83d\udcc8 Iteration {iteration + 1}/{num_iterations}\")\n",
        "            print(f\"{'='*60}\")\n",
        "\n",
        "            iteration_start = time.time()\n",
        "\n",
        "            # Create batches for this iteration\n",
        "            num_batches = (len(train_prompts) + batch_size - 1) // batch_size\n",
        "\n",
        "            for batch_idx in range(num_batches):\n",
        "                # Get batch prompts\n",
        "                start_idx = batch_idx * batch_size\n",
        "                end_idx = min(start_idx + batch_size, len(train_prompts))\n",
        "                batch_prompts = train_prompts[start_idx:end_idx]\n",
        "\n",
        "                # Execute GRPO training step\n",
        "                step_metrics = grpo_learner.train_step(\n",
        "                    prompts=batch_prompts,\n",
        "                )\n",
        "\n",
        "                global_step += 1\n",
        "\n",
        "                # Store metrics\n",
        "                training_metrics[\"losses\"].append(step_metrics.get(\"loss\", 0.0))\n",
        "                training_metrics[\"rewards\"].append(step_metrics.get(\"mean_reward\", 0.0))\n",
        "                training_metrics[\"kl_divergences\"].append(step_metrics.get(\"kl_divergence\", 0.0))\n",
        "                training_metrics[\"steps\"].append(global_step)\n",
        "\n",
        "                # Log progress\n",
        "                if global_step % log_every == 0:\n",
        "                    print(f\"\\n   Step {global_step}:\")\n",
        "                    print(f\"      Loss: {step_metrics.get('loss', 0.0):.4f}\")\n",
        "                    print(f\"      Mean Reward: {step_metrics.get('mean_reward', 0.0):.4f}\")\n",
        "                    print(f\"      KL Divergence: {step_metrics.get('kl_divergence', 0.0):.4f}\")\n",
        "\n",
        "                # Evaluation\n",
        "                if global_step % eval_every == 0:\n",
        "                    print(f\"\\n   \ud83d\udcca Evaluation at step {global_step}:\")\n",
        "                    # Generate sample output\n",
        "                    sample_prompt = train_prompts[0]\n",
        "                    sample_output = grpo_learner.generate(\n",
        "                        prompts=[sample_prompt],\n",
        "                        max_tokens=GRPO_CONFIG[\"max_tokens_to_generate\"],\n",
        "                    )[0]\n",
        "\n",
        "                    # Validate output format\n",
        "                    has_format = validate_xml_format(sample_output)\n",
        "                    reasoning, answer = extract_xml_content(sample_output)\n",
        "\n",
        "                    print(f\"      Valid XML format: {has_format}\")\n",
        "                    if reasoning:\n",
        "                        reasoning_tokens = len(tokenizer.encode(reasoning))\n",
        "                        print(f\"      Reasoning tokens: {reasoning_tokens}\")\n",
        "                    print(f\"      Sample output preview: {sample_output[:200]}...\")\n",
        "\n",
        "                # Checkpoint\n",
        "                if global_step % checkpoint_every == 0:\n",
        "                    checkpoint_path = f\"{CHECKPOINT_DIR}/step_{global_step}\"\n",
        "                    grpo_learner.save_checkpoint(checkpoint_path)\n",
        "                    print(f\"\\n   \ud83d\udcbe Checkpoint saved: {checkpoint_path}\")\n",
        "\n",
        "            iteration_time = time.time() - iteration_start\n",
        "            print(f\"\\n   \u23f1\ufe0f Iteration {iteration + 1} completed in {iteration_time:.1f}s\")\n",
        "\n",
        "            # Iteration summary\n",
        "            recent_losses = training_metrics[\"losses\"][-num_batches:]\n",
        "            recent_rewards = training_metrics[\"rewards\"][-num_batches:]\n",
        "            print(f\"   \ud83d\udcca Iteration Summary:\")\n",
        "            print(f\"      Avg Loss: {sum(recent_losses)/len(recent_losses):.4f}\")\n",
        "            print(f\"      Avg Reward: {sum(recent_rewards)/len(recent_rewards):.4f}\")\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"\u2705 TRAINING COMPLETE!\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"   Total steps: {global_step}\")\n",
        "    print(f\"   Total time: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
        "    print(f\"   Final avg loss: {sum(training_metrics['losses'][-10:])/10:.4f}\")\n",
        "    print(f\"   Final avg reward: {sum(training_metrics['rewards'][-10:])/10:.4f}\")\n",
        "\n",
        "    # Save final checkpoint\n",
        "    print(f\"\\n\ud83d\udcbe Saving final checkpoint to {FINAL_DIR}...\")\n",
        "    grpo_learner.save_checkpoint(FINAL_DIR)\n",
        "    print(\"\u2705 Final checkpoint saved!\")\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\u26a0\ufe0f Training interrupted by user!\")\n",
        "    print(f\"   Completed steps: {global_step}\")\n",
        "    # Save emergency checkpoint\n",
        "    emergency_path = f\"{CHECKPOINT_DIR}/interrupted_step_{global_step}\"\n",
        "    grpo_learner.save_checkpoint(emergency_path)\n",
        "    print(f\"   Emergency checkpoint saved: {emergency_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n\u274c Training error: {e}\")\n",
        "    print(f\"   Last completed step: {global_step}\")\n",
        "    # Try to save checkpoint on error\n",
        "    try:\n",
        "        error_path = f\"{CHECKPOINT_DIR}/error_step_{global_step}\"\n",
        "        grpo_learner.save_checkpoint(error_path)\n",
        "        print(f\"   Error checkpoint saved: {error_path}\")\n",
        "    except:\n",
        "        print(\"   Could not save error checkpoint\")\n",
        "    raise\n",
        "\n",
        "# Display training summary plot\n",
        "print(\"\\n\ud83d\udcca Training Metrics Summary:\")\n",
        "print(f\"   Steps: {len(training_metrics['steps'])}\")\n",
        "print(f\"   Loss range: {min(training_metrics['losses']):.4f} - {max(training_metrics['losses']):.4f}\")\n",
        "print(f\"   Reward range: {min(training_metrics['rewards']):.4f} - {max(training_metrics['rewards']):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tJc7--0L1eH"
      },
      "source": [
        "## \ud83d\udce6 Task 5: Export LoRA Adapters and Create Kaggle Submission\n",
        "\n",
        "Package trained adapters for Kaggle submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yopqXC2zL1eI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create kaggle_upload directory\n",
        "KAGGLE_DIR = \"./kaggle_upload\"\n",
        "os.makedirs(KAGGLE_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"\u2705 Created Kaggle submission directory: {KAGGLE_DIR}\")\n",
        "print(\"\\n\ud83d\udccb Export checklist:\")\n",
        "print(\"   [ ] adapter_config.json - LoRA configuration\")\n",
        "print(\"   [ ] adapter_model.safetensors - LoRA weights\")\n",
        "print(\"   [ ] tokenizer files (if modified)\")\n",
        "print(\"   [ ] README with inference instructions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5rH7ZDzL1eI"
      },
      "outputs": [],
      "source": [
        "# Export LoRA Adapters using Tunix API\n",
        "print(\"\ud83d\udce6 Exporting LoRA adapters...\")\n",
        "\n",
        "import json\n",
        "import shutil\n",
        "from safetensors.flax import save_file as save_safetensors\n",
        "\n",
        "# Export LoRA weights from trained model\n",
        "print(\"\\n\ud83d\udce4 Extracting LoRA weights from actor model...\")\n",
        "\n",
        "try:\n",
        "    # Method 1: Use Tunix's built-in export (preferred)\n",
        "    grpo_learner.export_lora_adapters(\n",
        "        output_dir=KAGGLE_DIR,\n",
        "        format=\"safetensors\"\n",
        "    )\n",
        "    print(\"\u2705 LoRA adapters exported using Tunix API\")\n",
        "\n",
        "except AttributeError:\n",
        "    # Method 2: Manual extraction using JAX/Flax parameter filtering\n",
        "    print(\"   Using manual extraction method...\")\n",
        "    from flax import traverse_util\n",
        "\n",
        "    # Flatten nested params and filter for LoRA weights\n",
        "    flat_params = traverse_util.flatten_dict(actor_model.params, sep='/')\n",
        "    lora_weights = {k: v for k, v in flat_params.items() if 'lora' in k.lower()}\n",
        "\n",
        "    # Save in safetensors format\n",
        "    adapter_path = f\"{KAGGLE_DIR}/adapter_model.safetensors\"\n",
        "    save_safetensors(lora_weights, adapter_path)\n",
        "    print(f\"\u2705 LoRA weights saved: {adapter_path}\")\n",
        "\n",
        "# Create adapter_config.json\n",
        "adapter_config = {\n",
        "    \"peft_type\": \"LORA\",\n",
        "    \"task_type\": \"CAUSAL_LM\",\n",
        "    \"r\": LORA_CONFIG[\"rank\"],\n",
        "    \"lora_alpha\": LORA_CONFIG[\"alpha\"],\n",
        "    \"lora_dropout\": LORA_CONFIG[\"dropout\"],\n",
        "    \"target_modules\": LORA_CONFIG[\"target_modules\"],\n",
        "    \"inference_mode\": True,\n",
        "    \"base_model_name_or_path\": MODEL_ID,\n",
        "    \"bias\": \"none\",\n",
        "    \"fan_in_fan_out\": False,\n",
        "}\n",
        "\n",
        "config_path = f\"{KAGGLE_DIR}/adapter_config.json\"\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(adapter_config, f, indent=2)\n",
        "print(f\"\u2705 Config saved: {config_path}\")\n",
        "\n",
        "# Copy tokenizer files\n",
        "print(\"\\n\ud83d\udcc1 Copying tokenizer files...\")\n",
        "tokenizer_files = [\"tokenizer.json\", \"tokenizer_config.json\", \"special_tokens_map.json\"]\n",
        "for fname in tokenizer_files:\n",
        "    src = f\"{model_path}/{fname}\"\n",
        "    dst = f\"{KAGGLE_DIR}/{fname}\"\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy2(src, dst)\n",
        "        print(f\"   Copied: {fname}\")\n",
        "\n",
        "# Create README\n",
        "readme_content = f\"\"\"# Judicaita GRPO-Trained LoRA Adapters\n",
        "\n",
        "## Model Information\n",
        "\n",
        "- **Base Model**: {MODEL_ID}\n",
        "- **Training Method**: GRPO (Group Relative Policy Optimization)\n",
        "- **Framework**: Google Tunix + JAX/Flax\n",
        "- **LoRA Rank**: {LORA_CONFIG[\"rank\"]}\n",
        "- **LoRA Alpha**: {LORA_CONFIG[\"alpha\"]}\n",
        "- **Training Platform**: Google Colab TPU\n",
        "\n",
        "## Inference Usage\n",
        "\n",
        "### With Transformers + PEFT\n",
        "\n",
        "```python\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "# Load base model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"{MODEL_ID}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"{MODEL_ID}\")\n",
        "\n",
        "# Load LoRA adapters\n",
        "model = PeftModel.from_pretrained(\n",
        "    base_model,\n",
        "    \"./adapter_model\"  # Path to this directory\n",
        ")\n",
        "\n",
        "# Generate\n",
        "prompt = \"Your legal question here\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_length=512)\n",
        "response = tokenizer.decode(outputs[0])\n",
        "```\n",
        "\n",
        "### Expected Output Format\n",
        "\n",
        "The model generates responses in XML format:\n",
        "```xml\n",
        "<reasoning>\n",
        "Detailed legal reasoning with analysis...\n",
        "</reasoning>\n",
        "<answer>\n",
        "Final answer or conclusion\n",
        "</answer>\n",
        "```\n",
        "\n",
        "## Training Details\n",
        "\n",
        "- **Reward Function**: Composite (30% format + 30% length + 40% correctness)\n",
        "- **GRPO Beta (KL penalty)**: {GRPO_CONFIG[\"beta\"]}\n",
        "- **Num Generations**: {GRPO_CONFIG[\"num_generations\"]}\n",
        "- **Learning Rate**: {GRPO_CONFIG[\"learning_rate\"]}\n",
        "\n",
        "## Validation Criteria\n",
        "\n",
        "- Reasoning should be >= 100 tokens\n",
        "- Both XML tags must be present\n",
        "- Answer should be relevant to the question\n",
        "\n",
        "## License\n",
        "\n",
        "Same as base model ({MODEL_ID})\n",
        "\"\"\"\n",
        "\n",
        "with open(f\"{KAGGLE_DIR}/README.md\", 'w') as f:\n",
        "    f.write(readme_content)\n",
        "print(\"\u2705 README.md created\")\n",
        "\n",
        "# List exported files\n",
        "print(\"\\n\ud83d\udccb Exported files:\")\n",
        "for item in os.listdir(KAGGLE_DIR):\n",
        "    item_path = os.path.join(KAGGLE_DIR, item)\n",
        "    size = os.path.getsize(item_path) if os.path.isfile(item_path) else 0\n",
        "    print(f\"   {item}: {size/1024:.1f} KB\" if size > 0 else f\"   {item}/\")\n",
        "\n",
        "print(\"\\n\u2705 Export complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2eOl8I3L1eI"
      },
      "source": [
        "### Validate Exported Model\n",
        "\n",
        "Test the exported adapters with inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1MX-caUL1eI"
      },
      "outputs": [],
      "source": [
        "# Validate Exported Model with Inference\n",
        "print(\"\ud83e\uddea Running Inference Validation...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test prompts for validation\n",
        "test_prompts = [\n",
        "    \"Is a verbal contract enforceable in most jurisdictions?\",\n",
        "    \"What are the elements required to prove negligence?\",\n",
        "    \"Can a contract be voided if one party was under duress?\",\n",
        "]\n",
        "\n",
        "print(\"\\n\ud83d\udcdd Test Prompts:\")\n",
        "for i, prompt in enumerate(test_prompts, 1):\n",
        "    print(f\"   {i}. {prompt}\")\n",
        "\n",
        "# Generate responses using trained model\n",
        "print(\"\\n\ud83d\udd04 Generating responses with trained model...\")\n",
        "\n",
        "validation_results = []\n",
        "\n",
        "for i, prompt in enumerate(test_prompts):\n",
        "    # Create full prompt with system instructions\n",
        "    full_prompt = create_prompt_template(prompt)\n",
        "\n",
        "    # Generate response\n",
        "    try:\n",
        "        response = grpo_learner.generate(\n",
        "            prompts=[full_prompt],\n",
        "            max_tokens=GRPO_CONFIG[\"max_tokens_to_generate\"],\n",
        "            temperature=0.7,\n",
        "        )[0]\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\u274c Generation error for prompt {i+1}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # Validate format\n",
        "    has_valid_format = validate_xml_format(response)\n",
        "    reasoning, answer = extract_xml_content(response)\n",
        "\n",
        "    # Count reasoning tokens\n",
        "    reasoning_tokens = 0\n",
        "    if reasoning:\n",
        "        reasoning_tokens = len(tokenizer.encode(reasoning))\n",
        "\n",
        "    # Compute reward\n",
        "    reward = composite_reward_function(\n",
        "        [full_prompt],\n",
        "        [response],\n",
        "        [{\"ground_truth\": \"\"}],  # No ground truth for test prompts\n",
        "        tokenizer\n",
        "    )[0]\n",
        "\n",
        "    result = {\n",
        "        \"prompt\": prompt,\n",
        "        \"response\": response,\n",
        "        \"valid_format\": has_valid_format,\n",
        "        \"reasoning_tokens\": reasoning_tokens,\n",
        "        \"has_reasoning\": reasoning is not None,\n",
        "        \"has_answer\": answer is not None,\n",
        "        \"reward\": reward,\n",
        "    }\n",
        "    validation_results.append(result)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"\ud83d\udccb Test {i+1}: {prompt[:50]}...\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"   \u2713 Valid XML format: {has_valid_format}\")\n",
        "    print(f\"   \u2713 Reasoning tokens: {reasoning_tokens}\")\n",
        "    print(f\"   \u2713 Has reasoning: {reasoning is not None}\")\n",
        "    print(f\"   \u2713 Has answer: {answer is not None}\")\n",
        "    print(f\"   \u2713 Reward score: {reward:.3f}\")\n",
        "\n",
        "    if reasoning:\n",
        "        print(f\"\\n   \ud83d\udcdd Reasoning preview:\")\n",
        "        print(f\"      {reasoning[:200]}...\")\n",
        "    if answer:\n",
        "        print(f\"\\n   \ud83d\udca1 Answer:\")\n",
        "        print(f\"      {answer[:200]}\")\n",
        "\n",
        "# Summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\ud83d\udcca VALIDATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "valid_count = sum(1 for r in validation_results if r[\"valid_format\"])\n",
        "avg_reasoning_tokens = sum(r[\"reasoning_tokens\"] for r in validation_results) / len(validation_results) if validation_results else 0\n",
        "avg_reward = sum(r[\"reward\"] for r in validation_results) / len(validation_results) if validation_results else 0\n",
        "\n",
        "print(f\"   Total test prompts: {len(test_prompts)}\")\n",
        "print(f\"   Valid XML format: {valid_count}/{len(validation_results)} ({100*valid_count/len(validation_results):.0f}%)\" if validation_results else \"   No results\")\n",
        "print(f\"   Avg reasoning tokens: {avg_reasoning_tokens:.0f}\")\n",
        "print(f\"   Avg reward score: {avg_reward:.3f}\")\n",
        "\n",
        "# Quality assessment\n",
        "print(\"\\n\ud83d\udcc8 Quality Assessment:\")\n",
        "if avg_reward >= 0.7:\n",
        "    print(\"   \u2705 EXCELLENT: Model produces high-quality legal reasoning\")\n",
        "elif avg_reward >= 0.5:\n",
        "    print(\"   \u2705 GOOD: Model produces adequate legal reasoning\")\n",
        "elif avg_reward >= 0.3:\n",
        "    print(\"   \u26a0\ufe0f FAIR: Model needs more training for better quality\")\n",
        "else:\n",
        "    print(\"   \u274c POOR: Model requires significant improvement\")\n",
        "\n",
        "if valid_count == len(validation_results) and validation_results:\n",
        "    print(\"   \u2705 All outputs have valid XML format\")\n",
        "elif valid_count > 0:\n",
        "    print(f\"   \u26a0\ufe0f Some outputs missing proper XML tags ({len(validation_results) - valid_count} invalid)\")\n",
        "else:\n",
        "    print(\"   \u274c No outputs have valid XML format - check training\")\n",
        "\n",
        "print(\"\\n\u2705 Validation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX3n-IzVL1eI"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create zip archive\n",
        "def create_submission_zip(source_dir: str, output_file: str):\n",
        "    \"\"\"\n",
        "    Create a zip archive for Kaggle submission.\n",
        "\n",
        "    Args:\n",
        "        source_dir: Directory containing files to zip\n",
        "        output_file: Output zip file path\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(output_file, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(source_dir):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, source_dir)\n",
        "                zipf.write(file_path, arcname)\n",
        "                print(f\"   Added: {arcname}\")\n",
        "\n",
        "    # Get zip file size\n",
        "    size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
        "    return size_mb\n",
        "\n",
        "# Create submission\n",
        "submission_zip = \"./judicaita_submission.zip\"\n",
        "print(\"\ud83d\udce6 Creating Kaggle submission package...\")\n",
        "print(f\"   Source: {KAGGLE_DIR}\")\n",
        "print(f\"   Output: {submission_zip}\")\n",
        "print(\"\\n\ud83d\udcc4 Files included:\")\n",
        "\n",
        "try:\n",
        "    size = create_submission_zip(KAGGLE_DIR, submission_zip)\n",
        "    print(f\"\\n\u2705 Submission package created!\")\n",
        "    print(f\"   File: {submission_zip}\")\n",
        "    print(f\"   Size: {size:.2f} MB\")\n",
        "\n",
        "    print(\"\\n\ud83d\udccb Submission Checklist:\")\n",
        "    print(\"   \u2705 adapter_config.json\")\n",
        "    print(\"   \u2705 README.md with instructions\")\n",
        "    print(\"   \u26a0\ufe0f  adapter_model.safetensors (add after training)\")\n",
        "    print(\"   \u26a0\ufe0f  Validation results (add after testing)\")\n",
        "\n",
        "    print(\"\\n\ud83c\udfaf Next Steps:\")\n",
        "    print(\"   1. Complete GRPO training\")\n",
        "    print(\"   2. Export adapter weights to kaggle_upload/\")\n",
        "    print(\"   3. Run inference validation\")\n",
        "    print(\"   4. Re-run this cell to create final zip\")\n",
        "    print(\"   5. Upload to Kaggle competition\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\u274c Error creating zip: {e}\")\n",
        "    print(\"   Make sure kaggle_upload directory has content\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00EHM5U8L1eI"
      },
      "source": [
        "### \ud83d\udd27 Troubleshooting Guide\n",
        "\n",
        "#### Tunix Import Errors\n",
        "- **ModuleNotFoundError: No module named 'tunix'**\n",
        "  - Ensure you installed with TPU extras: `pip install \"google-tunix[tpu]>=0.1.0,<=0.1.5\"`\n",
        "  - Restart runtime after installation\n",
        "  - Verify version: `python -c \"import tunix; print(tunix.__version__)\"`\n",
        "\n",
        "- **ImportError: cannot import name 'GRPOLearner'**\n",
        "  - Check Tunix version >= 0.1.0 (max available: 0.1.5)\n",
        "  - Verify correct import path: `from tunix.rl.grpo.grpo_learner import GRPOLearner`\n",
        "  - Note: API may vary between versions; check Tunix documentation for your version\n",
        "\n",
        "#### JAX/TPU Initialization Issues\n",
        "- **RuntimeError: TPU not found**\n",
        "  - Verify Colab runtime is set to TPU: Runtime \u2192 Change runtime type \u2192 TPU\n",
        "  - Try restarting the runtime completely\n",
        "  - Check TPU quota in Google Cloud Console if using custom project\n",
        "\n",
        "- **JAX version mismatch errors**\n",
        "  - Install JAX with TPU support: `pip install \"jax[tpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html`\n",
        "  - JAX 0.4+ requires TPU VMs and is NOT supported on Colab TPU\n",
        "  - Restart runtime after JAX installation\n",
        "  - Verify: `python -c \"import jax; print(jax.__version__, jax.devices())\"`\n",
        "\n",
        "- **jax_cuda12_plugin warnings**\n",
        "  - These warnings are expected and harmless for TPU training\n",
        "  - They appear because Colab environments may have GPU packages pre-installed\n",
        "  - You can safely ignore them when using TPU runtime\n",
        "\n",
        "#### RLCluster Configuration Errors\n",
        "- **ValueError: Mesh shape mismatch**\n",
        "  - Ensure mesh is created with correct number of devices\n",
        "  - Check `len(jax.devices())` matches expected TPU cores\n",
        "  - For TPU v2-8, expect 8 devices\n",
        "\n",
        "- **Sharding errors during training**\n",
        "  - Verify data_sharding is compatible with batch size\n",
        "  - Reduce batch_size to 1 or 2 for debugging\n",
        "  - Check model dtype is bfloat16 for TPU\n",
        "\n",
        "#### Memory Errors (OOM)\n",
        "- **Out of Memory during rollout generation**\n",
        "  - Reduce `num_generations` from 4 to 2\n",
        "  - Reduce `max_tokens_to_generate` from 512 to 256\n",
        "  - Reduce `batch_size` from 4 to 2 or 1\n",
        "\n",
        "- **Out of Memory during backward pass**\n",
        "  - Use smaller LoRA rank: try rank=8 instead of 16\n",
        "  - Enable gradient checkpointing if available\n",
        "  - Reduce sequence length\n",
        "\n",
        "#### Reward Function Issues\n",
        "- **Reward function signature mismatch**\n",
        "  - Tunix expects `reward_fn(prompts: List[str], outputs: List[str]) -> List[float]`\n",
        "  - Use `tunix_reward_wrapper` instead of `composite_reward_function` directly\n",
        "  - Ensure function returns Python list of floats, not numpy/jax arrays\n",
        "\n",
        "- **All rewards are 0.0**\n",
        "  - Check if model is generating XML tags properly\n",
        "  - Verify `extract_xml_content()` is working correctly\n",
        "  - Test reward function manually with sample outputs\n",
        "\n",
        "#### Checkpoint Issues\n",
        "- **Checkpoint save fails**\n",
        "  - Ensure checkpoint directory exists and is writable\n",
        "  - Check disk space (Colab has ~100GB limit)\n",
        "  - For large models, consider saving to Google Drive\n",
        "\n",
        "- **Checkpoint load fails**\n",
        "  - Verify checkpoint path is correct\n",
        "  - Check if checkpoint was saved completely (no interruption)\n",
        "  - Try loading with `strict=False` to ignore missing keys\n",
        "\n",
        "#### Training Not Converging\n",
        "- **Loss not decreasing**\n",
        "  - Try lower learning rate: 5e-6 or 1e-6\n",
        "  - Increase warmup steps\n",
        "  - Check if rewards are providing meaningful signal\n",
        "\n",
        "- **KL divergence too high**\n",
        "  - Increase beta (KL penalty coefficient)\n",
        "  - Reduce learning rate\n",
        "  - Ensure reference model is properly frozen\n",
        "\n",
        "- **Rewards not improving**\n",
        "  - Verify ground truth data quality\n",
        "  - Check reward function components individually\n",
        "  - Increase training iterations\n",
        "\n",
        "#### Export Issues\n",
        "- **safetensors export fails**\n",
        "  - Install safetensors: `pip install safetensors>=0.4.0`\n",
        "  - Verify weights are on CPU before saving\n",
        "  - Check file path permissions\n",
        "\n",
        "- **Exported adapters don't load in PyTorch**\n",
        "  - Ensure adapter_config.json has correct format\n",
        "  - Verify target_modules match PyTorch model layer names\n",
        "  - Check if conversion from Flax to PyTorch is needed\n",
        "\n",
        "#### Colab-Specific Issues\n",
        "- **Runtime disconnection during training**\n",
        "  - Save checkpoints frequently (every 50-100 steps)\n",
        "  - Keep browser tab active\n",
        "  - Consider using Colab Pro for longer runtime\n",
        "\n",
        "- **Storage limit reached**\n",
        "  - Clear old checkpoints: keep only latest + final\n",
        "  - Export to Google Drive\n",
        "  - Use smaller checkpoint format\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f1AnqMBL1eI"
      },
      "source": [
        "## \ud83c\udf89 Conclusion\n",
        "\n",
        "This notebook demonstrates end-to-end GRPO training for legal reasoning using Google Tunix on TPU:\n",
        "\n",
        "### What We Built\n",
        "\n",
        "1. \u2705 **TPU Setup**: Initialized JAX with TPU v2-8 using `colab_tpu.setup_tpu()`\n",
        "2. \u2705 **Model Loading**: Downloaded Gemma 3-1B-IT and initialized with LoRA adapters\n",
        "3. \u2705 **Dataset Preparation**: Created XML-formatted prompts for legal reasoning\n",
        "4. \u2705 **Reward Function**: Implemented composite scoring (format + length + correctness)\n",
        "5. \u2705 **GRPO Training**: Executed training with `GRPOLearner` and `RLCluster`\n",
        "6. \u2705 **Export**: Packaged LoRA adapters in safetensors format for submission\n",
        "\n",
        "### Training Results\n",
        "\n",
        "After training, the model should:\n",
        "- Generate responses in valid XML format (`<reasoning>...</reasoning><answer>...</answer>`)\n",
        "- Produce detailed legal reasoning (100+ tokens)\n",
        "- Provide accurate answers based on legal principles\n",
        "\n",
        "### Files Produced\n",
        "\n",
        "| File | Description |\n",
        "|------|-------------|\n",
        "| `adapter_config.json` | LoRA configuration for PEFT |\n",
        "| `adapter_model.safetensors` | Trained LoRA weights |\n",
        "| `README.md` | Inference instructions |\n",
        "| `judicaita_submission.zip` | Kaggle submission package |\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. **Upload to Kaggle**: Submit `judicaita_submission.zip` to the competition\n",
        "2. **Fine-tune Further**: Increase training iterations for better results\n",
        "3. **Add More Data**: Include additional legal reasoning examples\n",
        "4. **Evaluate on LegalBench**: Test on official benchmark tasks\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [Tunix Documentation](https://tunix.readthedocs.io/)\n",
        "- [Tunix GRPO Gemma Example](https://github.com/google/tunix/tree/main/examples/grpo_gemma)\n",
        "- [Judicaita Repository](https://github.com/clduab11/judicAIta)\n",
        "- [Gemma Model Cards](https://ai.google.dev/gemma)\n",
        "- [JAX TPU Guide](https://jax.readthedocs.io/en/latest/notebooks/TPU_Colab.html)\n",
        "\n",
        "### Troubleshooting & Support\n",
        "\n",
        "If you encounter issues:\n",
        "1. Check the Troubleshooting Guide section above\n",
        "2. Open an issue: https://github.com/clduab11/judicAIta/issues\n",
        "3. Review Tunix documentation for API changes\n",
        "\n",
        "### Contributing\n",
        "\n",
        "Improvements welcome! Submit a PR with:\n",
        "- Additional reward function components\n",
        "- Better data preprocessing\n",
        "- Performance optimizations\n",
        "- Documentation improvements\n",
        "\n",
        "---\n",
        "\n",
        "**Made with \u2764\ufe0f for the Kaggle hackathon and legal tech community**\n",
        "\n",
        "*Powered by Google Tunix, JAX, and Gemma*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}